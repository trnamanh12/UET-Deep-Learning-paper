{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:54:20.877803Z","iopub.status.busy":"2024-06-22T07:54:20.877313Z","iopub.status.idle":"2024-06-22T07:54:20.883093Z","shell.execute_reply":"2024-06-22T07:54:20.882126Z","shell.execute_reply.started":"2024-06-22T07:54:20.877772Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","# from data import SentenceDataset\n","import time\n","from transformers import AutoConfig, get_linear_schedule_with_warmup\n","from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:54:21.228252Z","iopub.status.busy":"2024-06-22T07:54:21.227588Z","iopub.status.idle":"2024-06-22T07:54:21.254715Z","shell.execute_reply":"2024-06-22T07:54:21.253841Z","shell.execute_reply.started":"2024-06-22T07:54:21.228218Z"},"trusted":true},"outputs":[{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:54:21.933917Z","iopub.status.busy":"2024-06-22T07:54:21.933553Z","iopub.status.idle":"2024-06-22T07:54:21.941938Z","shell.execute_reply":"2024-06-22T07:54:21.940748Z","shell.execute_reply.started":"2024-06-22T07:54:21.933888Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","# from transformers import BertTokenizerFast\n","\n","class SentenceDataset(Dataset):\n","\tdef __init__(self, src_sentence, tgt_sentence, tokenizer, max_length):\n","\t\tself.src = src_sentence \n","\t\tself.tgt = tgt_sentence\n","\t\tself.tokenizer = tokenizer\n","\t\tself.max_length = max_length \n","\n","\t# def get_tokenized_sentences(self, source_sentence, target_sentence):\n","\t#     tokenized_sentence = self.tokenizer(source_sentence, text_target =target_sentence, padding='max_length', truncation=True, return_tensors=\"pt\", max_length=self.max_length)\n","\t#     return tokenized_sentence\n","\n","\tdef __len__(self):\n","\t\treturn len(self.src)\n","\t\n","\tdef __getitem__(self, idx):\n","\t\tinputs = self.tokenizer(self.src[idx], text_target = self.tgt[idx], padding='max_length', truncation=True, return_tensors=\"pt\", max_length=self.max_length)\n","\n","\t\treturn {\n","\t\t\t'input_ids': inputs['input_ids'].squeeze(),\n","\t\t\t'attention_mask': inputs['attention_mask'].squeeze(),\n","\t\t\t'labels': inputs['labels'].squeeze()\n","\t\t}"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:54:22.947699Z","iopub.status.busy":"2024-06-22T07:54:22.947320Z","iopub.status.idle":"2024-06-22T07:54:23.687787Z","shell.execute_reply":"2024-06-22T07:54:23.686939Z","shell.execute_reply.started":"2024-06-22T07:54:22.947668Z"},"trusted":true},"outputs":[],"source":["en = []\n","with open('../data/train-en-vi/train.en', 'r', encoding='utf-8') as file:\n","\tfor line in file:\n","\t\ten.append(line.strip())  # strip() removes trailing newline characters\n","\n","vi = []\n","with open('../data/train-en-vi/train.vi', 'r', encoding='utf-8') as file:\n","\tfor line in file:\n","\t\tvi.append(line.strip())  # strip() removes trailing newline characters\n","\t\t\n","en_valid = []\n","with open('../data/dev-2012-en-vi/tst2012.en', 'r', encoding='utf-8') as file:\n","\tfor line in file:\n","\t\ten_valid.append(line.strip())  # strip() removes trailing newline characters\n","\n","vi_valid = []\n","with open('../data/dev-2012-en-vi/tst2012.vi', 'r', encoding='utf-8') as file:\n","\tfor line in file:\n","\t\tvi_valid.append(line.strip())  # strip() removes trailing newline characters\n","\n","train_data_src = en[2269:(2269+4096)]\n","train_data_trg= vi[2269:(2269+4096)]\n","valid_data_src = en_valid[269:(269+512)]\n","valid_data_trg= vi_valid[269:(269+512)]\n","test_data_src = en_valid[4:(4+256)]\n","test_data_trg= vi_valid[4:(4+256)]"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["with open('../data/bilingual_data/en.txt', 'r', encoding='utf-8') as file:\n","\tfor line in file:\n","\t\ttrain_data_src.append(line.strip())  # strip() removes trailing newline characters\n","with open('../data/bilingual_data/vi.txt', 'r', encoding='utf-8') as file:\n","\tfor line in file:\n","\t\ttrain_data_trg.append(line.strip())  # strip() removes trailing newline characters"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:54:23.893618Z","iopub.status.busy":"2024-06-22T07:54:23.892795Z","iopub.status.idle":"2024-06-22T07:54:23.897999Z","shell.execute_reply":"2024-06-22T07:54:23.896892Z","shell.execute_reply.started":"2024-06-22T07:54:23.893583Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:54:25.253107Z","iopub.status.busy":"2024-06-22T07:54:25.252736Z","iopub.status.idle":"2024-06-22T07:54:38.352033Z","shell.execute_reply":"2024-06-22T07:54:38.350629Z","shell.execute_reply.started":"2024-06-22T07:54:25.253081Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70b819a73fd44315bc0214735d9fbf68","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8011eaa923074ce2afd300cdee25fbb3","version_major":2,"version_minor":0},"text/plain":["sentencepiece.bpe.model:   0%|          | 0.00/1.41M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6cf8e95bc91f409d993a033e0ba588f7","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/1.69G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0241a4e55a204b35b2f891bae5da6fd6","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["MBartForConditionalGeneration(\n","  (model): MBartModel(\n","    (shared): Embedding(66773, 1024, padding_idx=1)\n","    (encoder): MBartEncoder(\n","      (embed_tokens): MBartScaledWordEmbedding(66773, 1024, padding_idx=1)\n","      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n","      (layers): ModuleList(\n","        (0-11): 12 x MBartEncoderLayer(\n","          (self_attn): MBartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): MBartDecoder(\n","      (embed_tokens): MBartScaledWordEmbedding(66773, 1024, padding_idx=1)\n","      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n","      (layers): ModuleList(\n","        (0-11): 12 x MBartDecoderLayer(\n","          (self_attn): MBartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MBartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=1024, out_features=66773, bias=False)\n",")"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"vinai/vinai-translate-en2vi-v2\", src_lang=\"en_XX\", tgt_lang=\"vi_VN\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"vinai/vinai-translate-en2vi-v2\")\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def template(en_sentence, condition):\n","\tif condition:\n","\t\ttemplated_sentence = [f\"Translate the following English sentence into Vietnamese: {sentence}\" for sentence in en_sentence]\n","\t\treturn templated_sentence\n","\telse:\n","\t\treturn en_sentence"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_data_src = template(train_data_src, True)\n","valid_data_src = template(valid_data_src, True)\n","test_data_src = template(test_data_src, True)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:54:38.389686Z","iopub.status.busy":"2024-06-22T07:54:38.388833Z","iopub.status.idle":"2024-06-22T07:54:38.394586Z","shell.execute_reply":"2024-06-22T07:54:38.393523Z","shell.execute_reply.started":"2024-06-22T07:54:38.389653Z"},"trusted":true},"outputs":[],"source":["train_dataset = SentenceDataset(train_data_src, train_data_trg, tokenizer, 128)\n","valid_dataset = SentenceDataset(valid_data_src, valid_data_trg, tokenizer, 128)\n","test_dataset = SentenceDataset(test_data_src, test_data_trg, tokenizer, 128)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:54:38.396603Z","iopub.status.busy":"2024-06-22T07:54:38.395778Z","iopub.status.idle":"2024-06-22T07:54:38.404719Z","shell.execute_reply":"2024-06-22T07:54:38.403700Z","shell.execute_reply.started":"2024-06-22T07:54:38.396566Z"},"trusted":true},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, shuffle=False)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:54:38.407023Z","iopub.status.busy":"2024-06-22T07:54:38.406245Z","iopub.status.idle":"2024-06-22T07:54:38.419770Z","shell.execute_reply":"2024-06-22T07:54:38.418718Z","shell.execute_reply.started":"2024-06-22T07:54:38.406991Z"},"trusted":true},"outputs":[],"source":["# Setup the optimizer\n","optimizer = optim.AdamW(model.parameters(), lr=3e-4, eps=1e-6, betas=(0.9,0.98), weight_decay =0.00001)\n","\n","# Number of training epochs\n","epochs = 1\n","\n","# Total number of training steps is [number of batches] x [number of epochs]\n","total_steps = len(train_loader) * epochs"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:54:47.828422Z","iopub.status.busy":"2024-06-22T07:54:47.827699Z","iopub.status.idle":"2024-06-22T07:54:47.832992Z","shell.execute_reply":"2024-06-22T07:54:47.831954Z","shell.execute_reply.started":"2024-06-22T07:54:47.828386Z"},"trusted":true},"outputs":[],"source":["scheduler = get_linear_schedule_with_warmup(optimizer, \n","\t\t\t\t\t\t\t\t\t\t\tnum_warmup_steps=int(0.01*total_steps),\n","\t\t\t\t\t\t\t\t\t\t\tnum_training_steps=total_steps)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:55:03.174752Z","iopub.status.busy":"2024-06-22T07:55:03.174375Z","iopub.status.idle":"2024-06-22T07:55:03.184685Z","shell.execute_reply":"2024-06-22T07:55:03.183612Z","shell.execute_reply.started":"2024-06-22T07:55:03.174724Z"},"trusted":true},"outputs":[],"source":["# Training loop\n","def train(model, loader, optimizer, scheduler, epochs, device):\n","\t# # Set the seed value all over the place to make this reproducible.\n","\t# seed_val = 42\n","\t# random.seed(seed_val)\n","\t# np.random.seed(seed_val)\n","\t# torch.manual_seed(seed_val)\n","\t# torch.cuda.manual_seed_all(seed_val)\n","\n","\t# Store the average loss after each epoch so we can plot them.\n","\tloss_values = []\n","\tfor epoch_i in range(0, epochs):\n","\t\t# Perform one full pass over the training set.\n","\t\tprint('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","\t\t# Measure how long the training epoch takes.\n","\t\tt0 = time.time()\n","\t\t\n","\t\t# Reset the total loss for this epoch.\n","\t\ttotal_loss = 0\n","\t\t\n","\t\t# Put the model into training mode.\n","\t\tmodel.train()\n","\n","\t\tfor step, batch in enumerate(loader):\n","\t\t\t# Progress update every 40 batches.\n","\t\t\tif step % 200 == 0 and not step == 0:\n","\t\t\t\tprint('  Batch {:>1,}  of  {:>1,}.    Elapsed: , Loss {:}'.format(step, len(loader) , total_loss / (step+1)))\n","\t\t\t# Always clear any previously calculated gradients before performing a backward pass.\n","\t\t\tmodel.zero_grad()        \n","\t\t\tbatch = {k: v.to(device) for k, v in batch.items()}\n","\t\t\t# Perform a forward pass (evaluate the model on this training batch).\n","\t\t\t# This will return the loss (rather than the model output) because we have provided the `labels`.\n","\t\t\toutputs = model(**batch)\n","\t\t\tloss = outputs.loss\n","\t\n","\t\t\tloss.backward()\n","\t\t\ttorch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\t\t\toptimizer.step()\n","\t\t\tscheduler.step()\n","\t\t\ttotal_loss += loss.item()\n","\t\tavg_train_loss = total_loss / len(loader)\n","\t\tprint(f\"Average training loss: {avg_train_loss:.2f}\")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:55:07.012654Z","iopub.status.busy":"2024-06-22T07:55:07.012283Z","iopub.status.idle":"2024-06-22T07:59:32.318918Z","shell.execute_reply":"2024-06-22T07:59:32.317929Z","shell.execute_reply.started":"2024-06-22T07:55:07.012625Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["======== Epoch 1 / 1 ========\n","  Batch 200  of  512.    Elapsed: , Loss 0.5924925121353634\n","  Batch 400  of  512.    Elapsed: , Loss 0.4475402319223209\n","Average training loss: 0.41\n"]}],"source":["train(model, train_loader, optimizer, scheduler, epochs, device)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["help(tokenizer)\t"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" </s>en_XX\n"]}],"source":["print(tokenizer.decode(tokenizer.prefix_tokens), tokenizer.decode(tokenizer.suffix_tokens))"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:59:32.321389Z","iopub.status.busy":"2024-06-22T07:59:32.321054Z","iopub.status.idle":"2024-06-22T07:59:33.477921Z","shell.execute_reply":"2024-06-22T07:59:33.477128Z","shell.execute_reply.started":"2024-06-22T07:59:32.321363Z"},"trusted":true},"outputs":[],"source":["# evaluate the model, get predictions and actuals\n","# BLEU score\n","from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n","\n","# def compute_bleu(predictions, actuals):\n","# \t# use the compute method of the BLEU metric\n","# \tbleu_score = corpus_bleu(list_of_references=[[actuals]], hypotheses=[predictions], smoothing_function=SmoothingFunction().method4) * 100\n","# \treturn bleu_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generate_predictions(model, loader, device):\n","\tpredictions = []\n","\tactuals = []\n","\trunning_loss = 0\n","\tfor batch in loader:\n","\t\t# Add batch to GPU\n","\t\tbatch = {k: v.to(device) for k, v in batch.items()}\n","\t\t# Telling the model not to compute or store gradients, saving memory and\n","\t\t# speeding up prediction\n","\t\twith torch.no_grad():\n","\t\t\toutputs = model(**batch)\n","\t\t\trunning_loss += outputs.loss\n","\n","\t\t# Get the top k largest predicted token ids\n","\t\t# topk_probas, topk_ids = torch.topk(outputs.logits, 5)\n","\n","\t\t# If we have a batch size of more than 1, we need to flatten the predictions\n","\t\t# sampling 1 ids from the topk ids\n","\t\t# ids = torch.multinomial(F.softmax(topk_probas, dim=-1), num_samples=1)\n","\n","\t\t# map the ids to the actual tokens\n","\t\t# actuals_ids = torch.gather(input=topk_ids ,dim=-1, index=ids).squeeze() # shape (batch_size, 1)\n","\t\t# predicted_tokens = torch.argmax(outputs.logits, dim=2)\n","\t\t# If we have a batch size of more than 1, we need to flatten the predictions\n","\t\t# and the target labels to be able to use the compute method from the\n","\t\t# datasets object\n","\t\t# predictions.extend(predicted_tokens)\n","\t\t# predictions.extend(actuals_ids) #\n","\t\t# actuals.extend(batch[\"labels\"])\n","\treturn running_loss/len(loader)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:59:33.479587Z","iopub.status.busy":"2024-06-22T07:59:33.479222Z","iopub.status.idle":"2024-06-22T07:59:33.486678Z","shell.execute_reply":"2024-06-22T07:59:33.485541Z","shell.execute_reply.started":"2024-06-22T07:59:33.479553Z"},"trusted":true},"outputs":[],"source":["def translate_en2vi(en_text: str, tokenizer_en2vi, model_en2vi, max_len) -> str:\n","\tinput_ids = tokenizer_en2vi(en_text, padding = 'max_length', truncation = True, max_length = max_len,  return_tensors=\"pt\").input_ids\n","\tinput_ids = input_ids.to(device)\n","\toutput_ids = model_en2vi.generate(\n","\t\tinput_ids,\n","\t\tdecoder_start_token_id=tokenizer_en2vi.lang_code_to_id[\"vi_VN\"],\n","\t\tnum_return_sequences=1,\n","\t\tnum_beams=5,\n","\t\tearly_stopping=True\n","\t)\n","\tvi_text = tokenizer_en2vi.batch_decode(output_ids, skip_special_tokens=True)\n","\t# vi_text = \" \".join(vi_text)\n","\treturn vi_text\n","\n","# en_text = [\"How are you? Are you okay?\", \"Nice to meet you\"]\n","# print(translate_en2vi(en_text, tokenizer, model, 32))\n","\n","# en_text = \"i haven't been to a public gym before when i exercise in a private space i feel more comfortable\"\n","# print(translate_en2vi(en_text))"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:59:33.488712Z","iopub.status.busy":"2024-06-22T07:59:33.488448Z","iopub.status.idle":"2024-06-22T07:59:33.498481Z","shell.execute_reply":"2024-06-22T07:59:33.497546Z","shell.execute_reply.started":"2024-06-22T07:59:33.488690Z"},"trusted":true},"outputs":[],"source":["# generation and calculation of BLEU score\n","def generate_and_calc_bleu( dataset, target, batch_size, tokenizer, model, device):\n","\tmodel.eval()\n","\tfor i in range(0, len(dataset), batch_size):\n","\t\tbatch = dataset[i:i+batch_size]\n","\t\tlabels = target[i: i+batch_size]\n","\t\t# Add batch to GPU\n","\t\t# batch only contains raw list of sentences\n","\t\tvi_predict = translate_en2vi(batch\t, tokenizer, model, 128)\n","\t\t# Telling the model not to compute or store gradients, saving memory and\n","\t\t# speeding up prediction\n","\t\tvi_target = [[s] for s in labels]\n","\t\tbleu_score = corpus_bleu(list_of_references=vi_target, hypotheses=vi_predict, smoothing_function=SmoothingFunction().method4) * 100\n","\t\treturn bleu_score"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:50:45.737370Z","iopub.status.busy":"2024-06-22T07:50:45.737026Z","iopub.status.idle":"2024-06-22T07:50:46.142072Z","shell.execute_reply":"2024-06-22T07:50:46.141021Z","shell.execute_reply.started":"2024-06-22T07:50:45.737345Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:59:33.499689Z","iopub.status.busy":"2024-06-22T07:59:33.499412Z","iopub.status.idle":"2024-06-22T07:59:43.030825Z","shell.execute_reply":"2024-06-22T07:59:43.029776Z","shell.execute_reply.started":"2024-06-22T07:59:33.499666Z"},"trusted":true},"outputs":[{"data":{"text/plain":["79.49787844610934"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["generate_and_calc_bleu(train_data_src, train_data_trg, 32, tokenizer, model, device)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T07:59:43.032228Z","iopub.status.busy":"2024-06-22T07:59:43.031925Z","iopub.status.idle":"2024-06-22T07:59:49.344693Z","shell.execute_reply":"2024-06-22T07:59:49.343745Z","shell.execute_reply.started":"2024-06-22T07:59:43.032203Z"},"trusted":true},"outputs":[{"data":{"text/plain":["61.320531682080535"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["generate_and_calc_bleu(valid_data_src, valid_data_trg, 32, tokenizer, model, device)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T08:01:22.020020Z","iopub.status.busy":"2024-06-22T08:01:22.018934Z","iopub.status.idle":"2024-06-22T08:01:22.376229Z","shell.execute_reply":"2024-06-22T08:01:22.374860Z","shell.execute_reply.started":"2024-06-22T08:01:22.019970Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T08:01:43.203718Z","iopub.status.busy":"2024-06-22T08:01:43.202839Z","iopub.status.idle":"2024-06-22T08:01:46.963835Z","shell.execute_reply":"2024-06-22T08:01:46.963115Z","shell.execute_reply.started":"2024-06-22T08:01:43.203687Z"},"trusted":true},"outputs":[{"data":{"text/plain":["59.91576993096669"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["generate_and_calc_bleu(test_data_src, test_data_trg, 32, tokenizer, model, device)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/trnmah/mambaforge/envs/practic1/lib/python3.10/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n","\n","  return torch._C._cuda_getDeviceCount() > 0\n"]},{"data":{"text/plain":["False"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import torch; torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5204452,"sourceId":8681463,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.1.undefined"}},"nbformat":4,"nbformat_minor":4}
