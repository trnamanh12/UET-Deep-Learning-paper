{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:44:44.931753Z","iopub.status.busy":"2024-06-13T11:44:44.930859Z","iopub.status.idle":"2024-06-13T11:44:49.362450Z","shell.execute_reply":"2024-06-13T11:44:49.361556Z","shell.execute_reply.started":"2024-06-13T11:44:44.931712Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","# from data import SentenceDataset\n","# from w2v import Word2Vec\n","# from model import EncoderRNN, DecoderRNN\n","from transformers import BertTokenizer, BertModel\n","from torch.utils.data import DataLoader, Dataset\n","import time"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:44:49.365216Z","iopub.status.busy":"2024-06-13T11:44:49.364454Z","iopub.status.idle":"2024-06-13T11:44:49.371635Z","shell.execute_reply":"2024-06-13T11:44:49.370351Z","shell.execute_reply.started":"2024-06-13T11:44:49.365175Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0]\n"]}],"source":["import sys\n","print(sys.version)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:44:49.373130Z","iopub.status.busy":"2024-06-13T11:44:49.372813Z","iopub.status.idle":"2024-06-13T11:44:49.413941Z","shell.execute_reply":"2024-06-13T11:44:49.413006Z","shell.execute_reply.started":"2024-06-13T11:44:49.373101Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:44:49.416085Z","iopub.status.busy":"2024-06-13T11:44:49.415797Z","iopub.status.idle":"2024-06-13T11:44:49.426487Z","shell.execute_reply":"2024-06-13T11:44:49.425564Z","shell.execute_reply.started":"2024-06-13T11:44:49.416060Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["12.1\n"]}],"source":["print(torch.version.cuda)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:44:51.275281Z","iopub.status.busy":"2024-06-13T11:44:51.274888Z","iopub.status.idle":"2024-06-13T11:44:51.283746Z","shell.execute_reply":"2024-06-13T11:44:51.282585Z","shell.execute_reply.started":"2024-06-13T11:44:51.275249Z"},"trusted":true},"outputs":[],"source":["class SentenceDataset(Dataset):\n","    def __init__(self, src_sentence, tgt_sentence, tokenizer, max_length):\n","        self.src = src_sentence \n","        self.tgt = tgt_sentence\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length \n","\n","    def get_tokenized_sentences(self, sentence):\n","        tokenized_sentence = self.tokenizer(sentence, padding='max_length', truncation=True, return_tensors=\"pt\", max_length=self.max_length)\n","        return tokenized_sentence['input_ids']\n","\n","    def __len__(self):\n","        return len(self.src)\n","    \n","    def __getitem__(self, idx):\n","        tokenized_src = self.get_tokenized_sentences(self.src[idx])\n","        tokenized_tgt = self.get_tokenized_sentences(self.tgt[idx])\n","        return {\n","            'src': tokenized_src.squeeze(0),\n","            'tgt': tokenized_tgt.squeeze(0),\n","        }"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:44:51.967450Z","iopub.status.busy":"2024-06-13T11:44:51.966625Z","iopub.status.idle":"2024-06-13T11:44:51.974130Z","shell.execute_reply":"2024-06-13T11:44:51.973035Z","shell.execute_reply.started":"2024-06-13T11:44:51.967416Z"},"trusted":true},"outputs":[],"source":["class Word2Vec(nn.Module):\n","\tdef __init__(self, vocab_size, embed_size, BERT = False): \n","\t\tsuper(Word2Vec, self).__init__()\n","\t\tif BERT:\n","\t\t\tmodel = BertModel.from_pretrained('bert-base-multilingual-cased')\n","\t\t\tself.embeddings = model.embeddings.word_embeddings\n","\t\t\tself.embeddings.requires_grad_(False)\n","\t\telse:\t\n","\t\t\tself.embeddings = nn.Embedding(vocab_size, embed_size)\n","\t\t\ttorch.nn.init.normal_(self.embeddings.weight, mean=0, std=0.02)\n","\tdef forward(self, x):\n","\t\tx = self.embeddings(x)\n","\t\treturn x"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:44:54.086104Z","iopub.status.busy":"2024-06-13T11:44:54.085731Z","iopub.status.idle":"2024-06-13T11:44:54.103283Z","shell.execute_reply":"2024-06-13T11:44:54.102217Z","shell.execute_reply.started":"2024-06-13T11:44:54.086073Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class EncoderRNN(nn.Module):\n","\tdef __init__(self,vocab_size, input_size, hidden_size, BERT, dropout=0.1):\n","\t\tsuper(EncoderRNN, self).__init__()\n","\t\tself.embedding = Word2Vec(vocab_size, input_size, BERT)\n","\t\tself.hidden_size = hidden_size\n","\t\tself.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n","\t\tself.dropout = nn.Dropout(dropout)\n","\n","\tdef forward(self, input):\n","\t\tembedded = self.dropout(self.embedding(input))\n","\t\toutput, hidden = self.rnn(embedded)\n","\t\treturn output, hidden\n","\n","# We should input both encoder and decoder is embedding vector, not input index\n","\n","class DecoderRNN(nn.Module):\n","\tdef __init__(self, vocab_size, input_size, hidden_size, sos_token, max_length, BERT, generator):\n","\t\tsuper(DecoderRNN, self).__init__()\n","\t\tself.rnn= nn.RNN(input_size, hidden_size, batch_first=True)\n","\t\tself.out = nn.Linear(hidden_size, vocab_size)\n","\t\tself.sos_token = sos_token # Start of Sentence token\n","\t\tself.max_length = max_length # Maximum length of the output sequence\n","\t\tself.embedding = Word2Vec(vocab_size, input_size, BERT)\n","\t\tself.generator = generator\n","\n","\tdef forward(self, encoder_outputs, encoder_hidden, device, target_tensor=None):\n","\t\tbatch_size = encoder_outputs.size(0)\n","\t\t# decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(self.sos_token)\n","\t\tdecoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(self.sos_token)\n","\t\tdecoder_hidden = encoder_hidden\n","\t\tdecoder_outputs = []\n","\t\t# target_tensor_size= target_tensor.size(1) # length of the target sequence\n","\t\tgenerated_tokens = decoder_input\n","\n","\t\tfor i in range(self.max_length): # input not include sos token, it range from 1 to max_length-1\n","\t\t\tdecoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n","\t\t\tdecoder_outputs.append(decoder_output)\n","\n","\t\t\tif target_tensor is not None:\n","\t\t\t\t# Teacher forcing: Feed the target as the next input\n","\t\t\t\tdecoder_input = target_tensor[:, i].unsqueeze(-1)  # Teacher forcing\n","\t\t\telse:\n","\t\t\t\t# Without teacher forcing: use its own predictions as the next input\n","\t\t\t\t# _, topi = decoder_output.topk(1) \n","\t\t\t\tdecoder_output = decoder_output.squeeze(1) # decoder_output.view(-1, decoder_output.size(-1))  | // decoder_output: [bs, 1, vocab_size] -> [bs, vocab_size\n","\t\t\t\ttopk_pros, topk_ids  = decoder_output.topk(5, dim=-1) # topk_ids: [batch_size, 5]\n","\t\t\t\tix = torch.multinomial(topk_pros, num_samples=1, generator=self.generator) # sample from the topk_pros [batch_size, 1]\n","\t\t\t\txcol = torch.gather(topk_ids, -1, ix) # gather the topk_ids with the index ix\n","\n","\t\t\t\tdecoder_input = xcol.detach()  # detach from history as input to the next time step\n","\t\t\t\tgenerated_tokens = torch.cat((generated_tokens, decoder_input), dim=1)\n","\n","\n","\t\tdecoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n","\t\tdecoder_outputs.append(decoder_output)\n","\t\t\n","\t\tdecoder_outputs = torch.cat(decoder_outputs, dim=1)\n","\t\treturn decoder_outputs, generated_tokens\n","\n","\tdef forward_step(self, input, hidden):\n","\t\toutput = self.embedding(input)\n","\t\toutput = F.relu(output)\n","\t\toutput, hidden = self.rnn(output, hidden)\n","\t\toutput = self.out(output)\n","\t\treturn output, hidden"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:44:55.029520Z","iopub.status.busy":"2024-06-13T11:44:55.029161Z","iopub.status.idle":"2024-06-13T11:44:56.012539Z","shell.execute_reply":"2024-06-13T11:44:56.011755Z","shell.execute_reply.started":"2024-06-13T11:44:55.029484Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"45cbe4dfd8bd43aeafc6dea83812b6b1","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b7d9c69db1548efbaf972e58a8acd0e","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43f91b22bbbd4108b16654f1df8ecfbc","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98f20617d4934235a829af0375e9c49f","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:46:44.502620Z","iopub.status.busy":"2024-06-13T11:46:44.501873Z","iopub.status.idle":"2024-06-13T11:46:44.819541Z","shell.execute_reply":"2024-06-13T11:46:44.818616Z","shell.execute_reply.started":"2024-06-13T11:46:44.502587Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Load data\n","en = []\n","with open('/kaggle/input/machinetranslationenvi/train.en', 'r', encoding='utf-8') as file:\n","\tfor line in file:\n","\t\ten.append(line.strip())  # strip() removes trailing newline characters\n","\n","vi = []\n","with open('/kaggle/input/machinetranslationenvi/train.vi', 'r', encoding='utf-8') as file:\n","\tfor line in file:\n","\t\tvi.append(line.strip())  # strip() removes trailing newline characters\n","\t\t\n","en_valid = []\n","with open('/kaggle/input/machinetranslationenvi/tst2012.en', 'r', encoding='utf-8') as file:\n","\tfor line in file:\n","\t\ten_valid.append(line.strip())  # strip() removes trailing newline characters\n","\n","vi_valid = []\n","with open('/kaggle/input/machinetranslationenvi/tst2012.vi', 'r', encoding='utf-8') as file:\n","\tfor line in file:\n","\t\tvi_valid.append(line.strip())  # strip() removes trailing newline characters\n","\n","train_data_src = en[2269:(2269+4096)]\n","train_data_trg= vi[2269:(2269+4096)]\n","valid_data_src = en_valid[269:(269+512)]\n","valid_data_trg= vi_valid[269:(269+512)]\n","test_data_src = en_valid[4:(4+256)]\n","test_data_trg= vi_valid[4:(4+256)]\n","\n","train_data = SentenceDataset(train_data_src, train_data_trg, tokenizer, max_length=64)\n","valid_data = SentenceDataset(valid_data_src, valid_data_trg, tokenizer, max_length=64)\n","test_data = SentenceDataset(test_data_src, test_data_trg, tokenizer, max_length=64)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:46:44.933839Z","iopub.status.busy":"2024-06-13T11:46:44.932980Z","iopub.status.idle":"2024-06-13T11:46:44.941577Z","shell.execute_reply":"2024-06-13T11:46:44.940570Z","shell.execute_reply.started":"2024-06-13T11:46:44.933803Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([64])"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["train_data[0]['src'].shape"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T12:00:16.637166Z","iopub.status.busy":"2024-06-13T12:00:16.636295Z","iopub.status.idle":"2024-06-13T12:00:16.642651Z","shell.execute_reply":"2024-06-13T12:00:16.641587Z","shell.execute_reply.started":"2024-06-13T12:00:16.637120Z"},"trusted":true},"outputs":[],"source":["train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n","valid_loader = DataLoader(valid_data, batch_size=64, shuffle=False)\n","test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:46:46.371124Z","iopub.status.busy":"2024-06-13T11:46:46.370153Z","iopub.status.idle":"2024-06-13T11:46:46.377981Z","shell.execute_reply":"2024-06-13T11:46:46.377014Z","shell.execute_reply.started":"2024-06-13T11:46:46.371085Z"},"trusted":true},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","\tdef __init__(self, config):\n","\t\tsuper(Seq2Seq, self).__init__()\n","\n","\t\tself.encoder = EncoderRNN(config['vocab_size'],config['input_size'], config['hidden_size'], \\\n","\t\t\t\t\t\t\t config['BERT'], config['dropout'])\n","\t\tself.decoder = DecoderRNN(config['vocab_size'], config['input_size'], config['hidden_size'], \\\n","\t\t\t\t\t\t\tconfig['sos_token'], config['max_length'] ,config['BERT'], config['generator'] )\n","\t\tself.device = config['device']\n","\t\n","\tdef forward(self, src, tgt):\n","\t\tencoder_output, encoder_hidden = self.encoder(src)\n","\t\tdecoder_output = self.decoder(encoder_output, encoder_hidden, self.device, tgt)\n","\t\treturn decoder_output # [bs, seqlen, vocab_size]"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:46:47.730758Z","iopub.status.busy":"2024-06-13T11:46:47.729737Z","iopub.status.idle":"2024-06-13T11:46:47.736958Z","shell.execute_reply":"2024-06-13T11:46:47.735979Z","shell.execute_reply.started":"2024-06-13T11:46:47.730711Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x785fba49ea70>"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["generator = torch.Generator(device=device)\n","generator.manual_seed(42+222)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:46:48.846146Z","iopub.status.busy":"2024-06-13T11:46:48.844740Z","iopub.status.idle":"2024-06-13T11:46:48.850374Z","shell.execute_reply":"2024-06-13T11:46:48.849308Z","shell.execute_reply.started":"2024-06-13T11:46:48.846090Z"},"trusted":true},"outputs":[],"source":["BERT = False"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:59:54.416939Z","iopub.status.busy":"2024-06-13T11:59:54.416194Z","iopub.status.idle":"2024-06-13T11:59:54.422232Z","shell.execute_reply":"2024-06-13T11:59:54.421310Z","shell.execute_reply.started":"2024-06-13T11:59:54.416902Z"},"trusted":true},"outputs":[],"source":["config = {\n","    'vocab_size': tokenizer.vocab_size,\n","    'input_size': 768 if BERT else 128 ,\n","    'hidden_size': 256,\n","\t'BERT': BERT,\n","\t'dropout': 0.1,\n","\t'sos_token': tokenizer.convert_tokens_to_ids('[CLS]'),\n","\t'max_length': 64-2,\n","\t'device' : device,\n","    'generator': generator\n","\n","}"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:59:54.770780Z","iopub.status.busy":"2024-06-13T11:59:54.769996Z","iopub.status.idle":"2024-06-13T11:59:55.759624Z","shell.execute_reply":"2024-06-13T11:59:55.758742Z","shell.execute_reply.started":"2024-06-13T11:59:54.770745Z"},"trusted":true},"outputs":[],"source":["model = Seq2Seq(config).to(device)\n"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:59:56.746074Z","iopub.status.busy":"2024-06-13T11:59:56.745696Z","iopub.status.idle":"2024-06-13T11:59:56.750354Z","shell.execute_reply":"2024-06-13T11:59:56.749342Z","shell.execute_reply.started":"2024-06-13T11:59:56.746045Z"},"trusted":true},"outputs":[],"source":["# model = torch.compile(model)"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:59:56.964165Z","iopub.status.busy":"2024-06-13T11:59:56.963833Z","iopub.status.idle":"2024-06-13T11:59:56.969749Z","shell.execute_reply":"2024-06-13T11:59:56.968646Z","shell.execute_reply.started":"2024-06-13T11:59:56.964138Z"},"trusted":true},"outputs":[],"source":["optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:59:58.544759Z","iopub.status.busy":"2024-06-13T11:59:58.543930Z","iopub.status.idle":"2024-06-13T11:59:58.549071Z","shell.execute_reply":"2024-06-13T11:59:58.547956Z","shell.execute_reply.started":"2024-06-13T11:59:58.544724Z"},"trusted":true},"outputs":[],"source":["critertion = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:48:41.753786Z","iopub.status.busy":"2024-06-13T11:48:41.753406Z","iopub.status.idle":"2024-06-13T11:48:41.759383Z","shell.execute_reply":"2024-06-13T11:48:41.758426Z","shell.execute_reply.started":"2024-06-13T11:48:41.753755Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.float16 \n"," cuda\n"]}],"source":["MixedPrecision = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16\n","print(MixedPrecision, \"\\n\", device)"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:48:42.164424Z","iopub.status.busy":"2024-06-13T11:48:42.164029Z","iopub.status.idle":"2024-06-13T11:48:42.170790Z","shell.execute_reply":"2024-06-13T11:48:42.169524Z","shell.execute_reply.started":"2024-06-13T11:48:42.164392Z"},"trusted":true},"outputs":[{"data":{"text/plain":["False"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_bf16_supported()"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T12:00:20.116398Z","iopub.status.busy":"2024-06-13T12:00:20.115789Z","iopub.status.idle":"2024-06-13T12:00:20.125965Z","shell.execute_reply":"2024-06-13T12:00:20.124998Z","shell.execute_reply.started":"2024-06-13T12:00:20.116362Z"},"trusted":true},"outputs":[],"source":["def train (model, data, optimizer, critertion, device, epochs=1):\n","\tmodel.train()\n","\tstart = time.time()\n","\trunning_loss = 0\n","\tfor j in range(epochs):\n","\t\tfor i, batch in enumerate(data):\n","\t\t\tsrc = batch['src'].to(device)\n","\t\t\ttgt = batch['tgt'].to(device)\n","\t\t\toptimizer.zero_grad()\n","\t\t\twith torch.autocast(device_type=device, dtype=MixedPrecision):\n","\t\t\t\toutput, _ = model(src, tgt[:, 1:-1])\n","\t\t\t\toutput = output.reshape(-1, output.size(-1))\n","\t\t\t\tloss = critertion(output, tgt[:, 1:].contiguous().view(-1))\n","\t\t\tloss.backward()\n","\t\t\toptimizer.step()\n","\t\t\ttorch.cuda.synchronize()\n","\t\t\trunning_loss += (loss.item())\n","\t\t\tif (i+1) % 10 == 0:\n","\t\t\t\tprint(f'Epoch: {j}, step: {i}, Loss: {loss.item()/i}')\n","\tend = time.time()\n","\tprint(f'Time: {end-start}, Loss: {running_loss/len(data)}')"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T12:00:20.458302Z","iopub.status.busy":"2024-06-13T12:00:20.457940Z","iopub.status.idle":"2024-06-13T12:04:19.072956Z","shell.execute_reply":"2024-06-13T12:04:19.071984Z","shell.execute_reply.started":"2024-06-13T12:00:20.458272Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0, step: 9, Loss: 0.8977607091267904\n","Epoch: 0, step: 19, Loss: 0.27186406286139236\n","Epoch: 0, step: 29, Loss: 0.12406638572955954\n","Epoch: 0, step: 39, Loss: 0.09667082321949494\n","Epoch: 0, step: 49, Loss: 0.06533774064511669\n","Epoch: 0, step: 59, Loss: 0.053951489723334876\n","Epoch: 1, step: 9, Loss: 0.3614708052741157\n","Epoch: 1, step: 19, Loss: 0.21360309500443309\n","Epoch: 1, step: 29, Loss: 0.11652185999113938\n","Epoch: 1, step: 39, Loss: 0.08890020541655712\n","Epoch: 1, step: 49, Loss: 0.0752775425813636\n","Epoch: 1, step: 59, Loss: 0.05640941555217161\n","Epoch: 2, step: 9, Loss: 0.39022061559889054\n","Epoch: 2, step: 19, Loss: 0.17647448338960348\n","Epoch: 2, step: 29, Loss: 0.11509426708879142\n","Epoch: 2, step: 39, Loss: 0.08288267331245618\n","Epoch: 2, step: 49, Loss: 0.057459072190888076\n","Epoch: 2, step: 59, Loss: 0.04983583143201925\n","Epoch: 3, step: 9, Loss: 0.33745402759975857\n","Epoch: 3, step: 19, Loss: 0.1468663215637207\n","Epoch: 3, step: 29, Loss: 0.11975921433547447\n","Epoch: 3, step: 39, Loss: 0.08549710420461801\n","Epoch: 3, step: 49, Loss: 0.059550222085446726\n","Epoch: 3, step: 59, Loss: 0.04934451943736965\n","Epoch: 4, step: 9, Loss: 0.3341940508948432\n","Epoch: 4, step: 19, Loss: 0.14595821029261538\n","Epoch: 4, step: 29, Loss: 0.09126678006402378\n","Epoch: 4, step: 39, Loss: 0.07186431762499687\n","Epoch: 4, step: 49, Loss: 0.05705941453271983\n","Epoch: 4, step: 59, Loss: 0.0530911138502218\n","Epoch: 5, step: 9, Loss: 0.323596715927124\n","Epoch: 5, step: 19, Loss: 0.1315770525681345\n","Epoch: 5, step: 29, Loss: 0.10019260439379461\n","Epoch: 5, step: 39, Loss: 0.0851445136926113\n","Epoch: 5, step: 49, Loss: 0.057099021210962414\n","Epoch: 5, step: 59, Loss: 0.04726321818464893\n","Epoch: 6, step: 9, Loss: 0.31837982601589626\n","Epoch: 6, step: 19, Loss: 0.13849200700458728\n","Epoch: 6, step: 29, Loss: 0.10365713875869224\n","Epoch: 6, step: 39, Loss: 0.06740347544352214\n","Epoch: 6, step: 49, Loss: 0.05485498175329091\n","Epoch: 6, step: 59, Loss: 0.044476864701610504\n","Epoch: 7, step: 9, Loss: 0.28494622972276473\n","Epoch: 7, step: 19, Loss: 0.13500202329535232\n","Epoch: 7, step: 29, Loss: 0.10304826703564875\n","Epoch: 7, step: 39, Loss: 0.0769333533751659\n","Epoch: 7, step: 49, Loss: 0.05212403803455586\n","Epoch: 7, step: 59, Loss: 0.04981873399120266\n","Epoch: 8, step: 9, Loss: 0.34661409589979386\n","Epoch: 8, step: 19, Loss: 0.1472435248525519\n","Epoch: 8, step: 29, Loss: 0.0866420104585845\n","Epoch: 8, step: 39, Loss: 0.0736997310931866\n","Epoch: 8, step: 49, Loss: 0.048414605004446845\n","Epoch: 8, step: 59, Loss: 0.0431378130185402\n","Epoch: 9, step: 9, Loss: 0.2685559060838487\n","Epoch: 9, step: 19, Loss: 0.14939635678341515\n","Epoch: 9, step: 29, Loss: 0.09595048016515272\n","Epoch: 9, step: 39, Loss: 0.06646360495151618\n","Epoch: 9, step: 49, Loss: 0.048349156671640824\n","Epoch: 9, step: 59, Loss: 0.045046531547934324\n","Time: 238.6090226173401, Loss: 31.583977710455656\n"]}],"source":["train(model, train_loader, optimizer, critertion, 'cuda', epochs=10)"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T12:04:31.219330Z","iopub.status.busy":"2024-06-13T12:04:31.218934Z","iopub.status.idle":"2024-06-13T12:04:31.231045Z","shell.execute_reply":"2024-06-13T12:04:31.230137Z","shell.execute_reply.started":"2024-06-13T12:04:31.219295Z"},"trusted":true},"outputs":[],"source":["import time\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","\n","def evaluation(model, data, criterion, device):\n","\tmodel.eval()\n","\tstart = time.time()\n","\tbleu_score = 0\n","\trunning_loss = 0\n","\ttotal_samples = 0  # Keep track of total samples for averaging BLEU\n","\n","\tfor i, batch in enumerate(data):\n","\t\tsrc = batch['src'].to(device)\n","\t\ttgt = batch['tgt'].to(device)\n","\t\twith torch.no_grad():\n","\t\t\twith torch.cuda.amp.autocast():  # Assuming you're using CUDA\n","\t\t\t\toutput, _ = model(src, tgt[:, 1:-1])\n","\t\t\t\toutput = output.reshape(-1, output.size(-1))\n","\t\t\t\tloss = criterion(output, tgt[:, 1:].contiguous().view(-1))\n","\t\t\toutput = output.argmax(dim=-1)\n","\t\t\toutput = output.view(src.size(0), -1)\n","\t\t\t# Calculate BLEU for each sentence and accumulate\n","\t\t\tfor ref, pred in zip(tgt[:, 1:], output):\n","\t\t\t\tbleu_score += sentence_bleu([ref.cpu().numpy().tolist()], pred.cpu().numpy().tolist(), smoothing_function=SmoothingFunction().method4)\n","\t\t\trunning_loss += loss.item()\n","\t\t\ttotal_samples += src.size(0)\n","\n","\tend = time.time()\n","\tavg_bleu_score = bleu_score / total_samples  # Average BLEU over all samples\n","\tprint(f'Time: {end - start}, Loss: {running_loss / len(data)}, BLEU: {avg_bleu_score}')"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T12:04:32.033541Z","iopub.status.busy":"2024-06-13T12:04:32.032499Z","iopub.status.idle":"2024-06-13T12:04:33.649262Z","shell.execute_reply":"2024-06-13T12:04:33.648209Z","shell.execute_reply.started":"2024-06-13T12:04:32.033481Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Time: 1.6103034019470215, Loss: 2.4693203270435333, BLEU: 0.6203853913719672\n"]}],"source":["evaluation(model, valid_loader, critertion, device)"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T12:04:33.775765Z","iopub.status.busy":"2024-06-13T12:04:33.775348Z","iopub.status.idle":"2024-06-13T12:04:33.781753Z","shell.execute_reply":"2024-06-13T12:04:33.780765Z","shell.execute_reply.started":"2024-06-13T12:04:33.775727Z"},"trusted":true},"outputs":[],"source":["def generate(model, sentence, tokenizer, device):\n","\tmodel.eval()\n","\tsentence = tokenizer(sentence, return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n","\twith torch.no_grad():\n","\t\t_ , generated_token = model(sentence['input_ids'].to(device), tgt=None)\n","\treturn generated_token "]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T12:04:33.985986Z","iopub.status.busy":"2024-06-13T12:04:33.985487Z","iopub.status.idle":"2024-06-13T12:04:34.045007Z","shell.execute_reply":"2024-06-13T12:04:34.044160Z","shell.execute_reply.started":"2024-06-13T12:04:33.985952Z"},"trusted":true},"outputs":[],"source":["    xinchao = generate(model, \"Hello\", tokenizer, device)"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T12:04:34.613429Z","iopub.status.busy":"2024-06-13T12:04:34.612758Z","iopub.status.idle":"2024-06-13T12:04:34.620601Z","shell.execute_reply":"2024-06-13T12:04:34.619555Z","shell.execute_reply.started":"2024-06-13T12:04:34.613394Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'[CLS] Nhưng một là tôi, một một.n. [PAD] [PAD] [SEP]n [PAD] [PAD] [PAD]y, chúng tôi, tôi có một, ta là tôi là là có một có một chúng chúng tôi. [SEP]y chúng một chúng tôi.n và một là có tôi là có tôi là tôi là có một có thể'"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(xinchao.squeeze(0))"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T12:04:36.004779Z","iopub.status.busy":"2024-06-13T12:04:36.004010Z","iopub.status.idle":"2024-06-13T12:04:36.067541Z","shell.execute_reply":"2024-06-13T12:04:36.066616Z","shell.execute_reply.started":"2024-06-13T12:04:36.004738Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'[CLS] Nhưng chúng chúng là chúng một, một chúng là tôi có thể, và chúng là có một có thể, một một có một một, chúng tôi, và tôi là chúng là là là chúng là có ta một, ta có thể một có là một, ta một là là là chúng chúng một, chúng'"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(generate(model, \"Even about seemingly personal and visceral things like who you &apos;re attracted to , you will start aping the beliefs of the people around you without even realizing that that &apos;s what you &apos;re doing .\", tokenizer, device).squeeze(0))"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T12:04:36.325574Z","iopub.status.busy":"2024-06-13T12:04:36.324906Z","iopub.status.idle":"2024-06-13T12:04:36.387367Z","shell.execute_reply":"2024-06-13T12:04:36.386459Z","shell.execute_reply.started":"2024-06-13T12:04:36.325536Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'[CLS] Chúng tôi có thể là chúng một chúng là là chúng chúng là chúng là là một, và chúng chúng chúng ta là một có thể, chúng là một, chúng chúng tôi có một một một là là tôi có tôi một một. [PAD]y, tôi có thể là tôi một. [PAD]n của bạn,'"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(generate(model, \"I love you\", tokenizer, device).squeeze(0))"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T12:04:36.876109Z","iopub.status.busy":"2024-06-13T12:04:36.875674Z","iopub.status.idle":"2024-06-13T12:04:36.937972Z","shell.execute_reply":"2024-06-13T12:04:36.936943Z","shell.execute_reply.started":"2024-06-13T12:04:36.876063Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'[CLS] Nhưng một chúng là là là có một chúng tôi, tôi một.n. [PAD]y, một, ta có chúng chúng ta một một là có ta là là một, chúng ta có tôi một là chúng chúng là một chúng ta, và là tôi là chúng một chúng tôi là chúng tôi. ; [SEP]'"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(generate(model, \"They had 348 different kinds of jam .\", tokenizer, device).squeeze(0))"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T12:04:44.036410Z","iopub.status.busy":"2024-06-13T12:04:44.035560Z","iopub.status.idle":"2024-06-13T12:04:44.546887Z","shell.execute_reply":"2024-06-13T12:04:44.546048Z","shell.execute_reply.started":"2024-06-13T12:04:44.036374Z"},"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), '/kaggle/working/seq2seq3.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5204452,"sourceId":8681463,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
