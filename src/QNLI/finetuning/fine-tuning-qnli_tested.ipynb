{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch\nfrom transformers import get_linear_schedule_with_warmup\nimport numpy as np\nimport random\nimport time\nimport datetime","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:17:23.873225Z","iopub.execute_input":"2024-06-18T05:17:23.874030Z","iopub.status.idle":"2024-06-18T05:17:30.246189Z","shell.execute_reply.started":"2024-06-18T05:17:23.874000Z","shell.execute_reply":"2024-06-18T05:17:30.245205Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset(\"nyu-mll/glue\", \"qnli\")","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:17:30.248048Z","iopub.execute_input":"2024-06-18T05:17:30.248517Z","iopub.status.idle":"2024-06-18T05:17:35.435927Z","shell.execute_reply.started":"2024-06-18T05:17:30.248491Z","shell.execute_reply":"2024-06-18T05:17:35.435003Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/35.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cde825f134844b04b6d3a9282f438659"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39e7215baa964d0d96051be2970ca807"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/872k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39c20fa4da9f49c6852d352c311b6666"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/877k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eef0ca47d28c48b0adf78c6cef82454b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/104743 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a06b3b7b86cf4cbfbb2662ff8c61d2fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/5463 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"408376bd50b6461fb3b29ffa0f76793a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/5463 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"092daf641f1d42f7a7ea8f73a7062f9f"}},"metadata":{}}]},{"cell_type":"code","source":"# Load the tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-cased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:17:35.437085Z","iopub.execute_input":"2024-06-18T05:17:35.437615Z","iopub.status.idle":"2024-06-18T05:17:38.601844Z","shell.execute_reply.started":"2024-06-18T05:17:35.437580Z","shell.execute_reply":"2024-06-18T05:17:38.600832Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ddcb7b48ea84cb1a7ed21c59ad43d76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f9f474c1d914fd5a36da8fd24f712ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a12d80edd0248c3a11061b7c5778135"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ed31af43f0a41429fcde6fc0fdf0d08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9de9a471fb8440039673d99b2f6d08ab"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.decode([101,102,103, 104], return_tensors='pt')","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:17:38.604040Z","iopub.execute_input":"2024-06-18T05:17:38.604345Z","iopub.status.idle":"2024-06-18T05:17:49.307433Z","shell.execute_reply.started":"2024-06-18T05:17:38.604321Z","shell.execute_reply":"2024-06-18T05:17:49.306516Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-06-18 05:17:40.217206: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-18 05:17:40.217325: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-18 05:17:40.340028: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'[CLS] [SEP] [MASK] [unused100]'"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.encode(\"Hello, [SEP] my dog is cute\")","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:17:49.308712Z","iopub.execute_input":"2024-06-18T05:17:49.309394Z","iopub.status.idle":"2024-06-18T05:17:49.315907Z","shell.execute_reply.started":"2024-06-18T05:17:49.309362Z","shell.execute_reply":"2024-06-18T05:17:49.315020Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[101, 8667, 117, 102, 1139, 3676, 1110, 10509, 102]"},"metadata":{}}]},{"cell_type":"code","source":"set(dataset['train']['label'])","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:17:49.317557Z","iopub.execute_input":"2024-06-18T05:17:49.318282Z","iopub.status.idle":"2024-06-18T05:17:49.396946Z","shell.execute_reply.started":"2024-06-18T05:17:49.318249Z","shell.execute_reply":"2024-06-18T05:17:49.396021Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{0, 1}"},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:17:49.398099Z","iopub.execute_input":"2024-06-18T05:17:49.398644Z","iopub.status.idle":"2024-06-18T05:17:49.404424Z","shell.execute_reply.started":"2024-06-18T05:17:49.398619Z","shell.execute_reply":"2024-06-18T05:17:49.403385Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['question', 'sentence', 'label', 'idx'],\n        num_rows: 104743\n    })\n    validation: Dataset({\n        features: ['question', 'sentence', 'label', 'idx'],\n        num_rows: 5463\n    })\n    test: Dataset({\n        features: ['question', 'sentence', 'label', 'idx'],\n        num_rows: 5463\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"random_train = dataset['train'].select(range(2269,12269))\nrandom_val = dataset['validation'].select(range(2269,3269))\nrandom_test = dataset['validation'].select(range(3269, 4269))","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:17:49.405616Z","iopub.execute_input":"2024-06-18T05:17:49.405865Z","iopub.status.idle":"2024-06-18T05:17:49.419045Z","shell.execute_reply.started":"2024-06-18T05:17:49.405844Z","shell.execute_reply":"2024-06-18T05:17:49.418390Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"sum(random_train['label'])","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:17:49.420077Z","iopub.execute_input":"2024-06-18T05:17:49.420426Z","iopub.status.idle":"2024-06-18T05:17:49.433137Z","shell.execute_reply.started":"2024-06-18T05:17:49.420396Z","shell.execute_reply":"2024-06-18T05:17:49.432347Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"5013"},"metadata":{}}]},{"cell_type":"code","source":"random_train['question'][0:5]","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:17:49.436446Z","iopub.execute_input":"2024-06-18T05:17:49.436974Z","iopub.status.idle":"2024-06-18T05:17:49.457136Z","shell.execute_reply.started":"2024-06-18T05:17:49.436943Z","shell.execute_reply":"2024-06-18T05:17:49.456303Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[\"Which artist guested on a live version of Queen's The Show Must Go On?\",\n 'marshall jefferson got involved in house music after hearing whose music?',\n \"What trend led to the decrease of Estonia's GDP?\",\n 'Which architects in the US and Britain still employ the Georgian style for private residences?',\n 'Who was responsible for crafting a new look for all Apple products?']"},"metadata":{}}]},{"cell_type":"code","source":"# Assuming dataset is a list of dicts with 'question', 'sentence', and 'label' keys\ndef template(template_type, dataset):\n\tif template_type == 'normal':\n\t\tinputs= tokenizer([f\"{q['question']}  [SEP] {q['sentence']}\" for q in dataset],\n\t\t\t\t\t\tpadding=True, truncation=True, return_tensors=\"pt\", max_length=256)\n\telif template_type == 'PCP':\n\t\tinputs= tokenizer([f\"{q['question']}  [MASK] , {q['context']}\" for q in dataset], \n\t\t\t\t\tpadding=True, truncation=True, return_tensors=\"pt\", max_length=256)\t\t\n\ttrain_labels = torch.tensor([q['label'] for q in dataset])\n\treturn inputs, train_labels\n\t\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:17:49.458323Z","iopub.execute_input":"2024-06-18T05:17:49.458612Z","iopub.status.idle":"2024-06-18T05:17:49.465350Z","shell.execute_reply.started":"2024-06-18T05:17:49.458589Z","shell.execute_reply":"2024-06-18T05:17:49.464322Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_inputs, train_outputs = template('normal',random_train)\nvalid_inputs, valid_outputs = template('normal',random_val)\ntest_inputs, test_outputs = template('normal',random_test)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:17:49.466638Z","iopub.execute_input":"2024-06-18T05:17:49.466958Z","iopub.status.idle":"2024-06-18T05:18:09.379183Z","shell.execute_reply.started":"2024-06-18T05:17:49.466930Z","shell.execute_reply":"2024-06-18T05:18:09.378359Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_data = TensorDataset(train_inputs['input_ids'],train_inputs['token_type_ids'],\n                            train_inputs['attention_mask'], train_outputs)\ntrain_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n\nvalid_data= TensorDataset(valid_inputs['input_ids'],valid_inputs['token_type_ids'],\n\t\t\t\t\t\t\tvalid_inputs['attention_mask'], valid_outputs)\nvalid_loader = DataLoader(valid_data, batch_size=32 )\n\ntest_data = TensorDataset(test_inputs['input_ids'],test_inputs['token_type_ids'],\n\t\t\t\t\t\t\ttest_inputs['attention_mask'], test_outputs)\ntest_loader = DataLoader(test_data, batch_size=32 )\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:18:09.380328Z","iopub.execute_input":"2024-06-18T05:18:09.380648Z","iopub.status.idle":"2024-06-18T05:18:09.387148Z","shell.execute_reply.started":"2024-06-18T05:18:09.380623Z","shell.execute_reply":"2024-06-18T05:18:09.386229Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n# model = torch.compile(model)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:18:09.388362Z","iopub.execute_input":"2024-06-18T05:18:09.388686Z","iopub.status.idle":"2024-06-18T05:18:09.687953Z","shell.execute_reply.started":"2024-06-18T05:18:09.388657Z","shell.execute_reply":"2024-06-18T05:18:09.687028Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"train_data[0][1].shape","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:18:09.689502Z","iopub.execute_input":"2024-06-18T05:18:09.689861Z","iopub.status.idle":"2024-06-18T05:18:09.695843Z","shell.execute_reply.started":"2024-06-18T05:18:09.689830Z","shell.execute_reply":"2024-06-18T05:18:09.694972Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"torch.Size([256])"},"metadata":{}}]},{"cell_type":"code","source":"\n# Freeze word_embeddings\ndef setting_model(model):\n\tfor param in model.bert.parameters():\n\t\tparam.requires_grad = False\n\n\tfor param in model.classifier.parameters():\n\t\tparam.requires_grad = True \n\n\tfor param in model.bert.embeddings.word_embeddings.parameters():\n\t\tparam.requires_grad = True \n\n# # Freeze position_embeddings\n# for param in model.bert.embeddings.position_embeddings.parameters():\n#     param.requires_grad = False\n\n# # Freeze token_type_embeddings\n# for param in model.bert.embeddings.token_type_embeddings.parameters():\n#     param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:49:12.088197Z","iopub.execute_input":"2024-06-17T18:49:12.088577Z","iopub.status.idle":"2024-06-17T18:49:12.094439Z","shell.execute_reply.started":"2024-06-17T18:49:12.088527Z","shell.execute_reply":"2024-06-17T18:49:12.093574Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"# setting model\nsetting_model(model)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:49:19.563291Z","iopub.execute_input":"2024-06-17T18:49:19.563671Z","iopub.status.idle":"2024-06-17T18:49:19.569036Z","shell.execute_reply.started":"2024-06-17T18:49:19.563642Z","shell.execute_reply":"2024-06-17T18:49:19.567986Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"# Function to calculate the accuracy of our predictions vs labels\ndef flat_accuracy(preds, labels):\n\tpred_flat = np.argmax(preds, axis=1).flatten()\n\tlabels_flat = labels.flatten()\n\treturn np.sum(pred_flat == labels_flat) / len(labels_flat)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:27:21.409725Z","iopub.execute_input":"2024-06-18T05:27:21.410090Z","iopub.status.idle":"2024-06-18T05:27:21.415585Z","shell.execute_reply.started":"2024-06-18T05:27:21.410061Z","shell.execute_reply":"2024-06-18T05:27:21.414430Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# model.add_adapter(\"qnli\", adapter_type=AdapterType.text_task)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T04:43:24.889359Z","iopub.execute_input":"2024-06-18T04:43:24.889692Z","iopub.status.idle":"2024-06-18T04:43:24.897572Z","shell.execute_reply.started":"2024-06-18T04:43:24.889662Z","shell.execute_reply":"2024-06-18T04:43:24.896667Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# model.add_adapter(\"qnli\", adapter_type=AdapterType.text_task, config=\"pfeiffer\")","metadata":{"execution":{"iopub.status.busy":"2024-06-18T04:43:24.898614Z","iopub.execute_input":"2024-06-18T04:43:24.898948Z","iopub.status.idle":"2024-06-18T04:43:24.905569Z","shell.execute_reply.started":"2024-06-18T04:43:24.898919Z","shell.execute_reply":"2024-06-18T04:43:24.904735Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from torch.optim import AdamW","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:18:09.696934Z","iopub.execute_input":"2024-06-18T05:18:09.697269Z","iopub.status.idle":"2024-06-18T05:18:09.703065Z","shell.execute_reply.started":"2024-06-18T05:18:09.697235Z","shell.execute_reply":"2024-06-18T05:18:09.702227Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Setup the optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-6, betas=(0.9,0.98), weight_decay =0.01)\n\n# Number of training epochs\nepochs = 2\n\n# Total number of training steps is [number of batches] x [number of epochs]\ntotal_steps = len(train_loader) * epochs\n\n# Create the learning rate scheduler\nscheduler = get_linear_schedule_with_warmup(optimizer, \n\t\t\t\t\t\t\t\t\t\t\tnum_warmup_steps=int(0.06*total_steps),\n\t\t\t\t\t\t\t\t\t\t\tnum_training_steps=total_steps)\n\n# Seed setting for reproducibility\nseed_val = 42\nrandom.seed(seed_val+222)\nnp.random.seed(seed_val+222)\ntorch.manual_seed(seed_val+222)\ntorch.cuda.manual_seed_all(seed_val+222)\n\n\n# Function for formatting elapsed times\ndef format_time(elapsed):\n\telapsed_rounded = int(round((elapsed)))\n\treturn str(datetime.timedelta(seconds=elapsed_rounded))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:18:09.704486Z","iopub.execute_input":"2024-06-18T05:18:09.704900Z","iopub.status.idle":"2024-06-18T05:18:09.714820Z","shell.execute_reply.started":"2024-06-18T05:18:09.704869Z","shell.execute_reply":"2024-06-18T05:18:09.713878Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"total_steps","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:18:09.716048Z","iopub.execute_input":"2024-06-18T05:18:09.716401Z","iopub.status.idle":"2024-06-18T05:18:09.724690Z","shell.execute_reply.started":"2024-06-18T05:18:09.716371Z","shell.execute_reply":"2024-06-18T05:18:09.723704Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"2500"},"metadata":{}}]},{"cell_type":"code","source":"# Training loop\ndef train(model, loader, optimizer, scheduler, epochs, device):\n\t# # Set the seed value all over the place to make this reproducible.\n\t# seed_val = 42\n\t# random.seed(seed_val)\n\t# np.random.seed(seed_val)\n\t# torch.manual_seed(seed_val)\n\t# torch.cuda.manual_seed_all(seed_val)\n\n\t# Store the average loss after each epoch so we can plot them.\n\tloss_values = []\n\tfor epoch_i in range(0, epochs):\n\t\t# Perform one full pass over the training set.\n\t\tprint('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n\t\t# Measure how long the training epoch takes.\n\t\tt0 = time.time()\n\t\t\n\t\t# Reset the total loss for this epoch.\n\t\ttotal_loss = 0\n\t\t\n\t\t# Put the model into training mode.\n\t\tmodel.train()\n\n\t\tfor step, batch in enumerate(loader):\n\t\t\t# Progress update every 40 batches.\n\t\t\tif step % 200 == 0 and not step == 0:\n\t\t\t\tprint('  Batch {:>1,}  of  {:>1,}.    Elapsed: , Loss {:}'.format(step, len(loader) , total_loss / (step+1)))\n\t\t\t# `batch` contains three pytorch tensors:\n\t\t\t#   [0]: input ids \n\t\t\t# \t[1]: token_type_ids\n\t\t\t#   [2]: attention masks\n\t\t\t#   [3]: labels \n\t\t\tb_input_ids = batch[0].to(device)\n\t\t\tb_token_type_ids = batch[1].to(device)\n\t\t\tb_input_mask = batch[2].to(device)\n\t\t\tb_labels = batch[3].to(device)\n\t\t\t\n\t\t\t# Always clear any previously calculated gradients before performing a backward pass.\n\t\t\tmodel.zero_grad()        \n\t\t\t\n\t\t\t# Perform a forward pass (evaluate the model on this training batch).\n\t\t\t# This will return the loss (rather than the model output) because we have provided the `labels`.\n\t\t\toutputs = model(b_input_ids, token_type_ids=b_token_type_ids, attention_mask=b_input_mask, labels=b_labels)\n\t\t\tloss = outputs.loss\n\t\n\t\t\tloss.backward()\n\t\t\ttorch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\t\t\toptimizer.step()\n\t\t\tscheduler.step()\n\t\t\ttotal_loss += loss.item()\n\t\tavg_train_loss = total_loss / len(loader)\n\t\tprint(f\"Average training loss: {avg_train_loss:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:18:09.726050Z","iopub.execute_input":"2024-06-18T05:18:09.726572Z","iopub.status.idle":"2024-06-18T05:18:09.736293Z","shell.execute_reply.started":"2024-06-18T05:18:09.726548Z","shell.execute_reply":"2024-06-18T05:18:09.735477Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train(model,train_loader, optimizer, scheduler, epochs, device)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:18:09.737570Z","iopub.execute_input":"2024-06-18T05:18:09.737988Z","iopub.status.idle":"2024-06-18T05:26:53.045841Z","shell.execute_reply.started":"2024-06-18T05:18:09.737949Z","shell.execute_reply":"2024-06-18T05:26:53.044783Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"======== Epoch 1 / 2 ========\n  Batch 200  of  1,250.    Elapsed: , Loss 0.6794830278970709\n  Batch 400  of  1,250.    Elapsed: , Loss 0.6444760851766403\n  Batch 600  of  1,250.    Elapsed: , Loss 0.6127527945995728\n  Batch 800  of  1,250.    Elapsed: , Loss 0.5927456688977657\n  Batch 1,000  of  1,250.    Elapsed: , Loss 0.5802010090707185\n  Batch 1,200  of  1,250.    Elapsed: , Loss 0.568572939589905\nAverage training loss: 0.57\n======== Epoch 2 / 2 ========\n  Batch 200  of  1,250.    Elapsed: , Loss 0.40790664258213777\n  Batch 400  of  1,250.    Elapsed: , Loss 0.4046985257203294\n  Batch 600  of  1,250.    Elapsed: , Loss 0.3956586726245388\n  Batch 800  of  1,250.    Elapsed: , Loss 0.39912180267692954\n  Batch 1,000  of  1,250.    Elapsed: , Loss 0.39573572378988925\n  Batch 1,200  of  1,250.    Elapsed: , Loss 0.3931263323848467\nAverage training loss: 0.39\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluation(model, loader, device):\n\tmodel.eval()\n\ttotal_eval_accuracy = 0\n\tfor batch in loader:\n\t\tb_input_ids,b_token_type_ids, b_input_mask, b_labels = batch\n\t\tb_input_ids = b_input_ids.to(device)\n\t\tb_token_type_ids = b_token_type_ids.to(device)\n\t\tb_input_mask = b_input_mask.to(device)\n\t\tb_labels = b_labels.to(device)\n\t\t\n\t\twith torch.no_grad():\n\t\t\toutputs = model(b_input_ids, token_type_ids=b_token_type_ids, attention_mask=b_input_mask)\n\t\t\n\t\tlogits = outputs.logits\n\t\tlogits = logits.detach().cpu().numpy()\n\t\tlabel_ids = b_labels.to('cpu').numpy()\n\t\t\n\t\t# Calculate the accuracy for this batch of test sentences\n\t\ttotal_eval_accuracy += flat_accuracy(logits, label_ids)\n\n\t# Report the final accuracy for this validation run\n\tavg_val_accuracy = total_eval_accuracy / len(loader)\n\tprint(\"Accuracy: {0:.2f}\".format(avg_val_accuracy))\n\n\treturn avg_val_accuracy\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:27:25.560988Z","iopub.execute_input":"2024-06-18T05:27:25.561373Z","iopub.status.idle":"2024-06-18T05:27:25.568971Z","shell.execute_reply.started":"2024-06-18T05:27:25.561347Z","shell.execute_reply":"2024-06-18T05:27:25.568054Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"evaluation(model, train_loader, device)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:27:25.809771Z","iopub.execute_input":"2024-06-18T05:27:25.810153Z","iopub.status.idle":"2024-06-18T05:28:38.101771Z","shell.execute_reply.started":"2024-06-18T05:27:25.810123Z","shell.execute_reply":"2024-06-18T05:28:38.100854Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Accuracy: 0.92\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"0.9247"},"metadata":{}}]},{"cell_type":"code","source":"evaluation(model, valid_loader, device)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:28:38.103430Z","iopub.execute_input":"2024-06-18T05:28:38.103717Z","iopub.status.idle":"2024-06-18T05:28:43.311398Z","shell.execute_reply.started":"2024-06-18T05:28:38.103692Z","shell.execute_reply":"2024-06-18T05:28:43.310455Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Accuracy: 0.83\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"0.830078125"},"metadata":{}}]},{"cell_type":"code","source":"evaluation(model, test_loader, device)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:28:43.312410Z","iopub.execute_input":"2024-06-18T05:28:43.312672Z","iopub.status.idle":"2024-06-18T05:28:48.192043Z","shell.execute_reply.started":"2024-06-18T05:28:43.312650Z","shell.execute_reply":"2024-06-18T05:28:48.190993Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Accuracy: 0.82\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"0.8154296875"},"metadata":{}}]},{"cell_type":"code","source":"del model\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:48:47.631407Z","iopub.execute_input":"2024-06-17T18:48:47.632029Z","iopub.status.idle":"2024-06-17T18:48:47.683123Z","shell.execute_reply.started":"2024-06-17T18:48:47.632001Z","shell.execute_reply":"2024-06-17T18:48:47.682134Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"# Save the model's state dictionary\ntorch.save(model.state_dict(), 'bert_finetuned_qnli.bin')\n\n# Optionally, save the entire model (not recommended due to potential issues when loading)\n# torch.save(model, 'bert_finetuned_qnli_full_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-06-17T19:07:03.133458Z","iopub.execute_input":"2024-06-17T19:07:03.134084Z","iopub.status.idle":"2024-06-17T19:07:03.756392Z","shell.execute_reply.started":"2024-06-17T19:07:03.134056Z","shell.execute_reply":"2024-06-17T19:07:03.755403Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"# Load the tokenizer and model architecture as before\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n\n# Load the model's state dictionary\nmodel.load_state_dict(torch.load('bert_finetuned_qnli.bin'))\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{},"execution_count":null,"outputs":[]}]}