{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:17:23.874030Z","iopub.status.busy":"2024-06-18T05:17:23.873225Z","iopub.status.idle":"2024-06-18T05:17:30.246189Z","shell.execute_reply":"2024-06-18T05:17:30.245205Z","shell.execute_reply.started":"2024-06-18T05:17:23.874000Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch\n","from transformers import get_linear_schedule_with_warmup\n","import numpy as np\n","import random\n","import time\n","import datetime\n","import transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:17:30.248517Z","iopub.status.busy":"2024-06-18T05:17:30.248048Z","iopub.status.idle":"2024-06-18T05:17:35.435927Z","shell.execute_reply":"2024-06-18T05:17:35.435003Z","shell.execute_reply.started":"2024-06-18T05:17:30.248491Z"},"trusted":true},"outputs":[],"source":["dataset = load_dataset(\"nyu-mll/glue\", \"qnli\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:17:35.437615Z","iopub.status.busy":"2024-06-18T05:17:35.437085Z","iopub.status.idle":"2024-06-18T05:17:38.601844Z","shell.execute_reply":"2024-06-18T05:17:38.600832Z","shell.execute_reply.started":"2024-06-18T05:17:35.437580Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Load the tokenizer and model\n","tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","model = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=2)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:17:38.604345Z","iopub.status.busy":"2024-06-18T05:17:38.604040Z","iopub.status.idle":"2024-06-18T05:17:49.307433Z","shell.execute_reply":"2024-06-18T05:17:49.306516Z","shell.execute_reply.started":"2024-06-18T05:17:38.604321Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-24 09:11:00.145984: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-24 09:11:01.227243: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"data":{"text/plain":["'[CLS] [SEP] [MASK] [unused100]'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode([101,102,103, 104], return_tensors='pt')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:17:49.318282Z","iopub.status.busy":"2024-06-18T05:17:49.317557Z","iopub.status.idle":"2024-06-18T05:17:49.396946Z","shell.execute_reply":"2024-06-18T05:17:49.396021Z","shell.execute_reply.started":"2024-06-18T05:17:49.318249Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{0, 1}"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["set(dataset['train']['label'])"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["[0, 1, 2, 3, 4]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:17:49.398644Z","iopub.status.busy":"2024-06-18T05:17:49.398099Z","iopub.status.idle":"2024-06-18T05:17:49.404424Z","shell.execute_reply":"2024-06-18T05:17:49.403385Z","shell.execute_reply.started":"2024-06-18T05:17:49.398619Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['question', 'sentence', 'label', 'idx'],\n","        num_rows: 104743\n","    })\n","    validation: Dataset({\n","        features: ['question', 'sentence', 'label', 'idx'],\n","        num_rows: 5463\n","    })\n","    test: Dataset({\n","        features: ['question', 'sentence', 'label', 'idx'],\n","        num_rows: 5463\n","    })\n","})"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:17:49.405865Z","iopub.status.busy":"2024-06-18T05:17:49.405616Z","iopub.status.idle":"2024-06-18T05:17:49.419045Z","shell.execute_reply":"2024-06-18T05:17:49.418390Z","shell.execute_reply.started":"2024-06-18T05:17:49.405844Z"},"trusted":true},"outputs":[],"source":["random_train = dataset['train'].select(range(2269,12269))\n","random_val = dataset['validation'].select(range(2269,3269))\n","random_test = dataset['validation'].select(range(3269, 4269))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:17:49.420426Z","iopub.status.busy":"2024-06-18T05:17:49.420077Z","iopub.status.idle":"2024-06-18T05:17:49.433137Z","shell.execute_reply":"2024-06-18T05:17:49.432347Z","shell.execute_reply.started":"2024-06-18T05:17:49.420396Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.5013"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["sum(random_train['label'])/len(random_train['label'])"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:17:49.436974Z","iopub.status.busy":"2024-06-18T05:17:49.436446Z","iopub.status.idle":"2024-06-18T05:17:49.457136Z","shell.execute_reply":"2024-06-18T05:17:49.456303Z","shell.execute_reply.started":"2024-06-18T05:17:49.436943Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[\"Which artist guested on a live version of Queen's The Show Must Go On?\",\n"," 'marshall jefferson got involved in house music after hearing whose music?',\n"," \"What trend led to the decrease of Estonia's GDP?\",\n"," 'Which architects in the US and Britain still employ the Georgian style for private residences?',\n"," 'Who was responsible for crafting a new look for all Apple products?']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["random_train['question'][0:5]"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:17:49.458612Z","iopub.status.busy":"2024-06-18T05:17:49.458323Z","iopub.status.idle":"2024-06-18T05:17:49.465350Z","shell.execute_reply":"2024-06-18T05:17:49.464322Z","shell.execute_reply.started":"2024-06-18T05:17:49.458589Z"},"trusted":true},"outputs":[],"source":["# Assuming dataset is a list of dicts with 'question', 'sentence', and 'label' keys\n","def template(template_type, dataset):\n","\tif template_type == 'normal':\n","\t\tinputs= tokenizer([f\"{q['question']}  [SEP] {q['sentence']}\" for q in dataset],\n","\t\t\t\t\t\tpadding=True, truncation=True, return_tensors=\"pt\", max_length=256)\n","\telif template_type == 'PCP':\n","\t\tinputs= tokenizer([f\"{q['question']} ? [MASK] , {q['context']}\" for q in dataset], \n","\t\t\t\t\tpadding=True, truncation=True, return_tensors=\"pt\", max_length=256)\t\t\n","\ttrain_labels = torch.tensor([q['label'] for q in dataset])\n","\treturn inputs, train_labels\n","\t\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:17:49.466958Z","iopub.status.busy":"2024-06-18T05:17:49.466638Z","iopub.status.idle":"2024-06-18T05:18:09.379183Z","shell.execute_reply":"2024-06-18T05:18:09.378359Z","shell.execute_reply.started":"2024-06-18T05:17:49.466930Z"},"trusted":true},"outputs":[],"source":["train_inputs, train_outputs = template('normal',random_train)\n","valid_inputs, valid_outputs = template('normal',random_val)\n","test_inputs, test_outputs = template('normal',random_test)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:18:09.380648Z","iopub.status.busy":"2024-06-18T05:18:09.380328Z","iopub.status.idle":"2024-06-18T05:18:09.387148Z","shell.execute_reply":"2024-06-18T05:18:09.386229Z","shell.execute_reply.started":"2024-06-18T05:18:09.380623Z"},"trusted":true},"outputs":[],"source":["train_data = TensorDataset(train_inputs['input_ids'],train_inputs['token_type_ids'],\n","\t\t\t\t\t\t\ttrain_inputs['attention_mask'], train_outputs)\n","train_loader = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n","\n","valid_data= TensorDataset(valid_inputs['input_ids'],valid_inputs['token_type_ids'],\n","\t\t\t\t\t\t\tvalid_inputs['attention_mask'], valid_outputs)\n","valid_loader = DataLoader(valid_data, batch_size=32 )\n","\n","test_data = TensorDataset(test_inputs['input_ids'],test_inputs['token_type_ids'],\n","\t\t\t\t\t\t\ttest_inputs['attention_mask'], test_outputs)\n","test_loader = DataLoader(test_data, batch_size=32 )\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:18:09.388686Z","iopub.status.busy":"2024-06-18T05:18:09.388362Z","iopub.status.idle":"2024-06-18T05:18:09.687953Z","shell.execute_reply":"2024-06-18T05:18:09.687028Z","shell.execute_reply.started":"2024-06-18T05:18:09.388657Z"},"trusted":true},"outputs":[{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Move model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# model = torch.compile(model)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:18:09.689861Z","iopub.status.busy":"2024-06-18T05:18:09.689502Z","iopub.status.idle":"2024-06-18T05:18:09.695843Z","shell.execute_reply":"2024-06-18T05:18:09.694972Z","shell.execute_reply.started":"2024-06-18T05:18:09.689830Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([256])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["train_data[0][1].shape"]},{"cell_type":"code","execution_count":108,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:49:12.088577Z","iopub.status.busy":"2024-06-17T18:49:12.088197Z","iopub.status.idle":"2024-06-17T18:49:12.094439Z","shell.execute_reply":"2024-06-17T18:49:12.093574Z","shell.execute_reply.started":"2024-06-17T18:49:12.088527Z"},"trusted":true},"outputs":[],"source":["\n","# Freeze word_embeddings\n","def only_classifier_embed(model):\n","\tfor param in model.bert.parameters():\n","\t\tparam.requires_grad = False\n","\n","\tfor param in model.classifier.parameters():\n","\t\tparam.requires_grad = True \n","\n","\tfor param in model.bert.embeddings.word_embeddings.parameters():\n","\t\tparam.requires_grad = True \n","\n","# # Freeze position_embeddings\n","# for param in model.bert.embeddings.position_embeddings.parameters():\n","#     param.requires_grad = False\n","\n","# # Freeze token_type_embeddings\n","# for param in model.bert.embeddings.token_type_embeddings.parameters():\n","#     param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def freeze_topk(model, k):\n","\ti_th = list(range(24 - k, 24))\n","\tlayer_counter = 0\n","# Iterate through the model's named parameters or children (depending on the level of granularity you need)\n","\tfor name, module in model.named_modules():\n","\t\t# Check if the module is of the type you're interested in (e.g., BertLayer for encoder layers in BERT)\n","\t\tif isinstance(module, transformers.models.bert.modeling_bert.BertLayer):\n","\t\t\t# Check if the current layer is the one you're interested in\n","\t\t\tif layer_counter in i_th:\n","\t\t\t\t# Print the layer's name and parameters\n","\t\t\t\tfor param_name, param in module.named_parameters():   \n","\t\t\t\t\tparam.requires_grad_ = False\n","\t\t\tlayer_counter += 1"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","True\n","True\n","True\n","True\n","True\n"]}],"source":["option = 'freeze_topk'\n","if option == 'freeze_topk':\n","\tfreeze_topk(model, 12)\n","elif option == 'only_classifier_embed':\n","\tonly_classifier_embed(model)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:27:21.410090Z","iopub.status.busy":"2024-06-18T05:27:21.409725Z","iopub.status.idle":"2024-06-18T05:27:21.415585Z","shell.execute_reply":"2024-06-18T05:27:21.414430Z","shell.execute_reply.started":"2024-06-18T05:27:21.410061Z"},"trusted":true},"outputs":[],"source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","\tpred_flat = np.argmax(preds, axis=1).flatten()\n","\tlabels_flat = labels.flatten()\n","\treturn np.sum(pred_flat == labels_flat) / len(labels_flat)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T04:43:24.898948Z","iopub.status.busy":"2024-06-18T04:43:24.898614Z","iopub.status.idle":"2024-06-18T04:43:24.905569Z","shell.execute_reply":"2024-06-18T04:43:24.904735Z","shell.execute_reply.started":"2024-06-18T04:43:24.898919Z"},"trusted":true},"outputs":[],"source":["# model.add_adapter(\"qnli\", adapter_type=AdapterType.text_task, config=\"pfeiffer\")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:18:09.697269Z","iopub.status.busy":"2024-06-18T05:18:09.696934Z","iopub.status.idle":"2024-06-18T05:18:09.703065Z","shell.execute_reply":"2024-06-18T05:18:09.702227Z","shell.execute_reply.started":"2024-06-18T05:18:09.697235Z"},"trusted":true},"outputs":[],"source":["from torch.optim import AdamW"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:18:09.704900Z","iopub.status.busy":"2024-06-18T05:18:09.704486Z","iopub.status.idle":"2024-06-18T05:18:09.714820Z","shell.execute_reply":"2024-06-18T05:18:09.713878Z","shell.execute_reply.started":"2024-06-18T05:18:09.704869Z"},"trusted":true},"outputs":[],"source":["# Setup the optimizer\n","optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-6, betas=(0.9,0.999), weight_decay =0.01)\n","\n","# Number of training epochs\n","epochs = 2\n","\n","# Total number of training steps is [number of batches] x [number of epochs]\n","total_steps = len(train_loader) * epochs\n","\n","# Create the learning rate scheduler\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","\t\t\t\t\t\t\t\t\t\t\tnum_warmup_steps=int(0.01*total_steps),\n","\t\t\t\t\t\t\t\t\t\t\tnum_training_steps=total_steps)\n","\n","# Seed setting for reproducibility\n","seed_val = 42\n","random.seed(seed_val+222)\n","np.random.seed(seed_val+222)\n","torch.manual_seed(seed_val+222)\n","torch.cuda.manual_seed_all(seed_val+222)\n","\n","\n","# Function for formatting elapsed times\n","def format_time(elapsed):\n","\telapsed_rounded = int(round((elapsed)))\n","\treturn str(datetime.timedelta(seconds=elapsed_rounded))\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:18:09.716401Z","iopub.status.busy":"2024-06-18T05:18:09.716048Z","iopub.status.idle":"2024-06-18T05:18:09.724690Z","shell.execute_reply":"2024-06-18T05:18:09.723704Z","shell.execute_reply.started":"2024-06-18T05:18:09.716371Z"},"trusted":true},"outputs":[{"data":{"text/plain":["2500"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["total_steps"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:18:09.726572Z","iopub.status.busy":"2024-06-18T05:18:09.726050Z","iopub.status.idle":"2024-06-18T05:18:09.736293Z","shell.execute_reply":"2024-06-18T05:18:09.735477Z","shell.execute_reply.started":"2024-06-18T05:18:09.726548Z"},"trusted":true},"outputs":[],"source":["# Training loop\n","def train(model, loader, optimizer, scheduler, epochs, device):\n","\t# # Set the seed value all over the place to make this reproducible.\n","\t# seed_val = 42\n","\t# random.seed(seed_val)\n","\t# np.random.seed(seed_val)\n","\t# torch.manual_seed(seed_val)\n","\t# torch.cuda.manual_seed_all(seed_val)\n","\n","\t# Store the average loss after each epoch so we can plot them.\n","\tloss_values = []\n","\tfor epoch_i in range(0, epochs):\n","\t\t# Perform one full pass over the training set.\n","\t\tprint('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","\t\t# Measure how long the training epoch takes.\n","\t\tt0 = time.time()\n","\t\t\n","\t\t# Reset the total loss for this epoch.\n","\t\ttotal_loss = 0\n","\t\t\n","\t\t# Put the model into training mode.\n","\t\tmodel.train()\n","\n","\t\tfor step, batch in enumerate(loader):\n","\t\t\t# Progress update every 40 batches.\n","\t\t\tif step % 200 == 0 and not step == 0:\n","\t\t\t\tprint('  Batch {:>1,}  of  {:>1,}.    Elapsed: , Loss {:}'.format(step, len(loader) , total_loss / (step+1)))\n","\t\t\t# `batch` contains three pytorch tensors:\n","\t\t\t#   [0]: input ids \n","\t\t\t# \t[1]: token_type_ids\n","\t\t\t#   [2]: attention masks\n","\t\t\t#   [3]: labels \n","# \t\t\tbatch.to(device, non_blocking=True)\n","\t\t\tb_input_ids = batch[0].to(device, non_blocking=True)\n","\t\t\tb_token_type_ids = batch[1].to(device, non_blocking=True)\n","\t\t\tb_input_mask = batch[2].to(device, non_blocking=True)\n","\t\t\tb_labels = batch[3].to(device, non_blocking=True)\n","\t\t\t\n","\t\t\t# Always clear any previously calculated gradients before performing a backward pass.\n","\t\t\tmodel.zero_grad(set_to_none= True)        \n","\t\t\t\n","\t\t\t# Perform a forward pass (evaluate the model on this training batch).\n","\t\t\t# This will return the loss (rather than the model output) because we have provided the `labels`.\n","\t\t\twith torch.autocast(device_type='cuda', dtype=torch.float32):\n"," \t\t\t\toutputs = model(b_input_ids, token_type_ids=b_token_type_ids, attention_mask=b_input_mask, labels=b_labels)\n","\t\t\tloss = outputs.loss\n","\t\n","\t\t\tloss.backward()\n","\t\t\ttorch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\t\t\toptimizer.step()\n","\t\t\tscheduler.step()\n","\t\t\ttotal_loss += loss.item()\n","\t\tavg_train_loss = total_loss / len(loader)\n","\t\tprint(f\"Average training loss: {avg_train_loss:.2f}\")"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:18:09.737988Z","iopub.status.busy":"2024-06-18T05:18:09.737570Z","iopub.status.idle":"2024-06-18T05:26:53.045841Z","shell.execute_reply":"2024-06-18T05:26:53.044783Z","shell.execute_reply.started":"2024-06-18T05:18:09.737949Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["======== Epoch 1 / 2 ========\n","  Batch 200  of  1,250.    Elapsed: , Loss 0.6794830278970709\n","  Batch 400  of  1,250.    Elapsed: , Loss 0.6444760851766403\n","  Batch 600  of  1,250.    Elapsed: , Loss 0.6127527945995728\n","  Batch 800  of  1,250.    Elapsed: , Loss 0.5927456688977657\n","  Batch 1,000  of  1,250.    Elapsed: , Loss 0.5802010090707185\n","  Batch 1,200  of  1,250.    Elapsed: , Loss 0.568572939589905\n","Average training loss: 0.57\n","======== Epoch 2 / 2 ========\n","  Batch 200  of  1,250.    Elapsed: , Loss 0.40790664258213777\n","  Batch 400  of  1,250.    Elapsed: , Loss 0.4046985257203294\n","  Batch 600  of  1,250.    Elapsed: , Loss 0.3956586726245388\n","  Batch 800  of  1,250.    Elapsed: , Loss 0.39912180267692954\n","  Batch 1,000  of  1,250.    Elapsed: , Loss 0.39573572378988925\n","  Batch 1,200  of  1,250.    Elapsed: , Loss 0.3931263323848467\n","Average training loss: 0.39\n"]}],"source":["train(model,train_loader, optimizer, scheduler, epochs, device)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:27:25.561373Z","iopub.status.busy":"2024-06-18T05:27:25.560988Z","iopub.status.idle":"2024-06-18T05:27:25.568971Z","shell.execute_reply":"2024-06-18T05:27:25.568054Z","shell.execute_reply.started":"2024-06-18T05:27:25.561347Z"},"trusted":true},"outputs":[],"source":["def evaluation(model, loader, device):\n","\tmodel.eval()\n","\ttotal_eval_accuracy = 0\n","\tfor batch in loader:\n","\t\tb_input_ids,b_token_type_ids, b_input_mask, b_labels = batch\n","\t\tb_input_ids = b_input_ids.to(device)\n","\t\tb_token_type_ids = b_token_type_ids.to(device)\n","\t\tb_input_mask = b_input_mask.to(device)\n","\t\tb_labels = b_labels.to(device)\n","\t\t\n","\t\twith torch.no_grad():\n","\t\t\toutputs = model(b_input_ids, token_type_ids=b_token_type_ids, attention_mask=b_input_mask)\n","\t\t\n","\t\tlogits = outputs.logits\n","\t\tlogits = logits.detach().cpu().numpy()\n","\t\tlabel_ids = b_labels.to('cpu').numpy()\n","\t\t\n","\t\t# Calculate the accuracy for this batch of test sentences\n","\t\ttotal_eval_accuracy += flat_accuracy(logits, label_ids)\n","\n","\t# Report the final accuracy for this validation run\n","\tavg_val_accuracy = total_eval_accuracy / len(loader)\n","\tprint(\"Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","\treturn avg_val_accuracy\n","\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:27:25.810153Z","iopub.status.busy":"2024-06-18T05:27:25.809771Z","iopub.status.idle":"2024-06-18T05:28:38.101771Z","shell.execute_reply":"2024-06-18T05:28:38.100854Z","shell.execute_reply.started":"2024-06-18T05:27:25.810123Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.92\n"]},{"data":{"text/plain":["0.9247"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["evaluation(model, train_loader, device)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:28:38.103717Z","iopub.status.busy":"2024-06-18T05:28:38.103430Z","iopub.status.idle":"2024-06-18T05:28:43.311398Z","shell.execute_reply":"2024-06-18T05:28:43.310455Z","shell.execute_reply.started":"2024-06-18T05:28:38.103692Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.83\n"]},{"data":{"text/plain":["0.830078125"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["evaluation(model, valid_loader, device)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T05:28:43.312672Z","iopub.status.busy":"2024-06-18T05:28:43.312410Z","iopub.status.idle":"2024-06-18T05:28:48.192043Z","shell.execute_reply":"2024-06-18T05:28:48.190993Z","shell.execute_reply.started":"2024-06-18T05:28:43.312650Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.82\n"]},{"data":{"text/plain":["0.8154296875"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["evaluation(model, test_loader, device)"]},{"cell_type":"code","execution_count":105,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:48:47.632029Z","iopub.status.busy":"2024-06-17T18:48:47.631407Z","iopub.status.idle":"2024-06-17T18:48:47.683123Z","shell.execute_reply":"2024-06-17T18:48:47.682134Z","shell.execute_reply.started":"2024-06-17T18:48:47.632001Z"},"trusted":true},"outputs":[],"source":["del model\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":121,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T19:07:03.134084Z","iopub.status.busy":"2024-06-17T19:07:03.133458Z","iopub.status.idle":"2024-06-17T19:07:03.756392Z","shell.execute_reply":"2024-06-17T19:07:03.755403Z","shell.execute_reply.started":"2024-06-17T19:07:03.134056Z"},"trusted":true},"outputs":[],"source":["# Save the model's state dictionary\n","torch.save(model.state_dict(), 'bert_finetuned_qnli.bin')\n","\n","# Optionally, save the entire model (not recommended due to potential issues when loading)\n","# torch.save(model, 'bert_finetuned_qnli_full_model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the tokenizer and model architecture as before\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n","\n","# Load the model's state dictionary\n","model.load_state_dict(torch.load('bert_finetuned_qnli.bin'))\n","\n","# Move model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
