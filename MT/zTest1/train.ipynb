{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trnmah/mambaforge/envs/practic1/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from data import SentenceDataset\n",
    "from w2v import Word2Vec\n",
    "from model import EncoderRNN, DecoderRNN\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load data\n",
    "en = []\n",
    "with open('/home/trnmah/final_projectDL/src/MT/data/train-en-vi/train.en', 'r', encoding='utf-8') as file:\n",
    "\tfor line in file:\n",
    "\t\ten.append(line.strip())  # strip() removes trailing newline characters\n",
    "\n",
    "vi = []\n",
    "with open('/home/trnmah/final_projectDL/src/MT/data/train-en-vi/train.vi', 'r', encoding='utf-8') as file:\n",
    "\tfor line in file:\n",
    "\t\tvi.append(line.strip())  # strip() removes trailing newline characters\n",
    "\t\t\n",
    "en_valid = []\n",
    "with open('/home/trnmah/final_projectDL/src/MT/data/dev-2012-en-vi/tst2012.en', 'r', encoding='utf-8') as file:\n",
    "\tfor line in file:\n",
    "\t\ten_valid.append(line.strip())  # strip() removes trailing newline characters\n",
    "\n",
    "vi_valid = []\n",
    "with open('/home/trnmah/final_projectDL/src/MT/data/dev-2012-en-vi/tst2012.vi', 'r', encoding='utf-8') as file:\n",
    "\tfor line in file:\n",
    "\t\tvi_valid.append(line.strip())  # strip() removes trailing newline characters\n",
    "\n",
    "train_data_src = en[2269:(2269+4096)]\n",
    "train_data_trg= vi[2269:(2269+4096)]\n",
    "valid_data_src = en_valid[269:(269+512)]\n",
    "valid_data_trg= vi_valid[269:(269+512)]\n",
    "test_data_src = en_valid[4:(4+256)]\n",
    "test_data_trg= vi_valid[4:(4+256)]\n",
    "\n",
    "train_data = SentenceDataset(train_data_src, train_data_trg, tokenizer, max_length=128)\n",
    "valid_data = SentenceDataset(valid_data_src, valid_data_trg, tokenizer, max_length=128)\n",
    "test_data = SentenceDataset(test_data_src, test_data_trg, tokenizer, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['src'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "\tdef __init__(self, config):\n",
    "\t\tsuper(Seq2Seq, self).__init__()\n",
    "\n",
    "\t\tself.encoder = EncoderRNN(config['vocab_size'],config['input_size'], config['hidden_size'], \\\n",
    "\t\t\t\t\t\t\t config['BERT'], config['dropout'])\n",
    "\t\tself.decoder = DecoderRNN(config['vocab_size'], config['input_size'], config['hidden_size'], \\\n",
    "\t\t\t\t\t\t\tconfig['sos_token'], config['max_length'] ,config['BERT'], config['generator'] )\n",
    "\t\tself.device = config['device']\n",
    "\t\n",
    "\tdef forward(self, src, tgt=None):\n",
    "\t\tencoder_output, encoder_hidden = self.encoder(src)\n",
    "\t\tdecoder_output = self.decoder(encoder_output, encoder_hidden, self.device, tgt)\n",
    "\t\treturn decoder_output # [bs, seqlen, vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7148e7bee430>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = torch.Generator(device=device)\n",
    "generator.manual_seed(42+222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'vocab_size': tokenizer.vocab_size,\n",
    "    'input_size': 128,\n",
    "    'hidden_size': 256,\n",
    "\t'BERT': False,\n",
    "\t'dropout': 0.1,\n",
    "\t'sos_token': tokenizer.convert_tokens_to_ids('[CLS]'),\n",
    "\t'max_length': 128-2,\n",
    "\t'device' : device,\n",
    "\t'generator': generator\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(config).to(device)\n",
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "critertion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (model, data, optimizer, critertion, device, epochs=1):\n",
    "\tmodel.train()\n",
    "\tstart = time.time()\n",
    "\trunning_loss = 0\n",
    "\tfor j in range(epochs):\n",
    "\t\tfor i, batch in enumerate(data):\n",
    "\t\t\tsrc = batch['src'].to(device)\n",
    "\t\t\ttgt = batch['tgt'].to(device)\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\twith torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "\t\t\t\toutput, _ = model(src, tgt[:, 1:-1])\n",
    "\t\t\t\tloss = critertion(output.view(-1, output.size(-1)), tgt[:, 1:].reshape(-1))\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\ttorch.cuda.synchronize()\n",
    "\t\t\trunning_loss += (loss.item())\n",
    "\t\t\tif (i+1) % 1000 == 0:\n",
    "\t\t\t\tprint(f'Epoch: {j}, step: {i}, Loss: {loss.item()/i}')\n",
    "\tend = time.time()\n",
    "\tprint(f'Time: {end-start}, Loss: {running_loss/len(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_loader, optimizer, critertion, device, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def evaluation(model, data, optimizer, criterion, device):\n",
    "\tmodel.eval()\n",
    "\tstart = time.time()\n",
    "\tbleu_score = 0\n",
    "\trunning_loss = 0\n",
    "\ttotal_samples = 0  # Keep track of total samples for averaging BLEU\n",
    "\n",
    "\tfor i, batch in enumerate(data):\n",
    "\t\tsrc = batch['src'].to(device)\n",
    "\t\ttgt = batch['tgt'].to(device)\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\twith torch.cuda.amp.autocast():  # Assuming you're using CUDA\n",
    "\t\t\t\toutput, _ = model(src, tgt[:, :-1])\n",
    "\t\t\t\toutput = output.reshape(-1, output.size(-1))\n",
    "\t\t\t\tloss = criterion(output, tgt[:, 1:].reshape(-1))\n",
    "\t\t\toutput = output.argmax(dim=-1)\n",
    "\t\t\toutput = output.view(src.size(0), -1)\n",
    "\t\t\t# Calculate BLEU for each sentence and accumulate\n",
    "\t\t\tfor ref, pred in zip(tgt[:, :-1], output):\n",
    "\t\t\t\tbleu_score += sentence_bleu([ref.cpu().numpy().tolist()], pred.cpu().numpy().tolist(), smoothing_function=SmoothingFunction().method4)\n",
    "\t\t\trunning_loss += loss.item()\n",
    "\t\t\ttotal_samples += src.size(0)\n",
    "\n",
    "\tend = time.time()\n",
    "\tavg_bleu_score = bleu_score / total_samples  # Average BLEU over all samples\n",
    "\tprint(f'Time: {end - start}, Loss: {running_loss / len(data)}, BLEU: {avg_bleu_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(32, 128)\n",
    "print(a[:, :128].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, sentence, tokenizer, device):\n",
    "\tmodel.eval()\n",
    "\tsentence = tokenizer(sentence, return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n",
    "\twith torch.no_grad():\n",
    "\t\t_ , generated_token = model(sentence['input_ids'].to(device))\n",
    "\treturn generated_token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(model, \"Hello\", tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_bleu_score(model, data, tokenizer)\n",
    "\tmodel.eval()\n",
    "\tstart = time.time()\n",
    "\trunning_loss = 0\n",
    "\tfor i, batch in enumerate(data):\n",
    "\t\tsrc = batch['src'].to(device)\n",
    "\t\ttgt = batch['tgt'].to(device)\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\twith torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "\t\t\t\toutput, _ = model(src, tgt[:, 1:-1])\n",
    "\t\t\t\toutput = output.view(-1, output.size(-1))\n",
    "\t\t\t\tloss = critertion(output, tgt[:, 1:].contiguous().view(-1))\n",
    "\t\trunning_loss += (loss.item())\n",
    "\tend = time.time()\n",
    "\tprint(f'Time: {end-start}, Loss: {running_loss/len(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def calculate_bleu_score(reference, candidate):\n",
    "    \"\"\"\n",
    "    Calculate the BLEU score for a candidate sentence against a reference sentence.\n",
    "\n",
    "    :param reference: list of words (reference sentence)\n",
    "    :param candidate: list of words (candidate sentence)\n",
    "    :return: BLEU score\n",
    "    \"\"\"\n",
    "    # Reference sentences are supposed to be a list of lists of words\n",
    "    reference = [reference]\n",
    "    \n",
    "    # Smoothing function to handle cases with zero counts\n",
    "    smoothing_function = SmoothingFunction().method1\n",
    "    \n",
    "    # Calculate BLEU score\n",
    "    bleu_score = sentence_bleu(reference, candidate, smoothing_function=smoothing_function)\n",
    "    \n",
    "    return bleu_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Corpus BLEU score: 0.8409\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "\n",
    "# List of reference and candidate sentences\n",
    "# references = [\n",
    "#     [['this', 'is', 'a', 'test']],\n",
    "#     [['another', 'test', 'sentence', 'is']]\n",
    "# ]\n",
    "# candidates = [\n",
    "#     ['this', 'is', 'a', 'test'],\n",
    "#     ['another', 'test', 'sentence', 'is']\n",
    "# ]\n",
    "references = [\n",
    "    [[102, 103,105, 203]],\n",
    "    [[104, 106, 108]]\n",
    "]\n",
    "candidates = [\n",
    "    [102, 103, 105, 203],\n",
    "\t[104, 106, 108]\n",
    "]\n",
    "print(len(references))\n",
    "# Calculate BLEU score\n",
    "corpus_bleu_score = corpus_bleu(references, candidates, smoothing_function=SmoothingFunction().method1)\n",
    "print(f\"Corpus BLEU score: {corpus_bleu_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'seq2seq.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practic1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
