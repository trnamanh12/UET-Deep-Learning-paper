{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:43:54.054253Z","iopub.status.busy":"2024-06-14T12:43:54.053361Z","iopub.status.idle":"2024-06-14T12:44:00.471062Z","shell.execute_reply":"2024-06-14T12:44:00.470273Z","shell.execute_reply.started":"2024-06-14T12:43:54.054218Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","# from data import SquadDataset\n","# from model import * \n","# from w2v import Word2Vec\n","from transformers import BertTokenizerFast, BertModel\n","from datasets import load_dataset\n","import math\n","import torch.optim as optim\n","import time"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:00.473028Z","iopub.status.busy":"2024-06-14T12:44:00.472566Z","iopub.status.idle":"2024-06-14T12:44:00.482621Z","shell.execute_reply":"2024-06-14T12:44:00.481705Z","shell.execute_reply.started":"2024-06-14T12:44:00.473000Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from transformers import BertTokenizer\n","\n","class SquadDataset(torch.utils.data.Dataset):\n","\t'''\n","\t- Creates batches dynamically by padding to the length of largest example\n","\t  in a given batch.\n","\t- Calulates character vectors for contexts and question.\n","\t- Returns tensors for training.\n","\t'''\n","\t\n","\tdef __init__(self, data, batch_size, tokenizer, max_len):\n","\t\t\n","\t\tself.batch_size = batch_size\n","\t\tdata = [data[i:i+self.batch_size] for i in range(0, len(data), self.batch_size)]\n","\t\tself.data = data\n","\t\t# self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\t\tself.tokenizer = tokenizer\n","\t\tself.max_len = max_len\n","\t\t\n","\tdef __len__(self):\n","\t\treturn len(self.data)\n","\t\n","\tdef __iter__(self):\n","\t\t'''\n","\t\tCreates batches of data and yields them.\n","\t\t\n","\t\tEach yield comprises of:\n","\t\t:padded_context: padded tensor of contexts for each batch \n","\t\t:padded_question: padded tensor of questions for each batch \n","\t\t:label: \n","\t\t\n","\t\t'''\n","\t\t\n","\t\tfor batch in self.data:\n","\t\t\tquestions = self.tokenizer(batch['question'], max_length = self.max_len, padding='max_length', truncation=True, return_tensors='pt')\n","\t\t\tcontexts = self.tokenizer(batch['sentence'], max_length = self.max_len, padding='max_length', truncation=True, return_tensors='pt')\n","\t\t\tlabels = torch.IntTensor(batch['label']).to(torch.int8)\n","\t\t\t# question, context include input_ids, attention_mask, token_type_ids\n","\t\t\tyield questions, contexts, labels\n","\t\t\t\n","\t\t\t"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:00.484142Z","iopub.status.busy":"2024-06-14T12:44:00.483790Z","iopub.status.idle":"2024-06-14T12:44:00.497273Z","shell.execute_reply":"2024-06-14T12:44:00.496445Z","shell.execute_reply.started":"2024-06-14T12:44:00.484118Z"},"trusted":true},"outputs":[],"source":["class Word2Vec(nn.Module):\n","\tdef __init__(self, vocab_size, embed_size, BERT = False): \n","\t\tsuper(Word2Vec, self).__init__()\n","\t\tif BERT:\n","\t\t\tmodel = BertModel.from_pretrained('bert-base-uncased')\n","\t\t\tself.embeddings = model.embeddings.word_embeddings\n","\t\t\tself.embeddings.requires_grad_(False)\n","\t\telse:\t\n","\t\t\tself.embeddings = nn.Embedding(vocab_size, embed_size)\n","\t\t\ttorch.nn.init.xavier_uniform_(self.embeddings.weight)\n","\tdef forward(self, x):\n","\t\tx = self.embeddings(x)\n","\t\treturn x\n","\t\n","\n","\n","class PositionalEmbedding(nn.Module):\n","\tdef __init__(self,embed_size, max_len, device):\n","\t\tsuper(PositionalEmbedding, self).__init__()\n","\t\tself.encoding = torch.zeros(max_len, embed_size, requires_grad=False, device=device)\n","\t\tpos = torch.arange(0, max_len, device=device).float().unsqueeze(1)\n","\t\t_2i = torch.arange(0, embed_size, 2, device=device).float()\n","\t\tself.encoding[:, 0::2] = torch.sin(pos/ torch.pow(10000, _2i/ embed_size)).to(device)\n","\t\tself.encoding[:, 1::2] = torch.cos(pos/ torch.pow(10000, _2i/ embed_size)).to(device)\n","\n","\tdef forward(self, x):\n","\t\t# bs, seqlen, embed_dim = x.size()\n","\t\t# pe_tensor = torch.zeros(seqlen, embed_dim)\n","\t\t# sin = [torch.sin(pos/ torch.pow(10000, torch.arange(0, embed_dim, 2)/ embed_dim)) for  pos in self.pos]\n","\t\t# cos = [torch.cos(pos/ torch.pow(10000, torch.arange(1, embed_dim, 2)/ embed_dim)) for pos in self.pos]\n","\t\t# pe_tensor[:, 0::2] = sin\n","\t\t# pe_tensor[:, 1::2] = cos\n","\t\t# pe_tensor = pe_tensor.unsqueeze(0).expand(bs, seqlen, embed_dim)\n","\t\tbs, seqlen, embed_dim = x.size()\n","\t\treturn self.encoding[:seqlen, :].expand(bs, seqlen, embed_dim)\n","\n","class WordEmbedding(nn.Module):\n","\tdef __init__(self, vocab_size, embed_size, max_len, device, BERT=False):\n","\t\tsuper(WordEmbedding, self).__init__()\n","\t\tself.word2vec = Word2Vec(vocab_size, embed_size, BERT)\n","\t\tself.positional_embedding = PositionalEmbedding( embed_size, max_len, device)\n","\t\n","\tdef forward(self, x):\n","\t\tx = self.word2vec(x)\n","\t\tx = x + self.positional_embedding(x)\n","\t\treturn x"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:00.499720Z","iopub.status.busy":"2024-06-14T12:44:00.499423Z","iopub.status.idle":"2024-06-14T12:44:00.533795Z","shell.execute_reply":"2024-06-14T12:44:00.532925Z","shell.execute_reply.started":"2024-06-14T12:44:00.499697Z"},"trusted":true},"outputs":[],"source":["class LayerNorm(nn.Module):\n","    def __init__(self, ndim, bias: bool = True, eps: float = 1e-5):\n","        super(LayerNorm, self).__init__()\n","        self.gamma = nn.Parameter(torch.ones(ndim))\n","        self.beta = nn.Parameter(torch.zeros(ndim))\n","        self.eps = eps\n","    \n","    def forward(self, x):\n","        mean = x.mean(-1, keepdim=True)\n","        std = x.std(-1, keepdim=True)\n","        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n","\n","class SelfAttention(nn.Module):\n","    def __init__(self, embed_size, nhead, dropout):\n","        super(SelfAttention, self).__init__()\n","        self.dropout = nn.Dropout(dropout)\n","        self.p_qkv = nn.Linear(embed_size, embed_size*3)\n","        torch.nn.init.xavier_uniform_(self.p_qkv.weight)\n","\n","        self.p_proj = nn.Linear(embed_size, embed_size)\n","        torch.nn.init.xavier_uniform_(self.p_proj.weight)\n","\n","        self.nhead = nhead\n","    \n","    def forward(self, x , attmask):   \n","        '''\n","        1. input q, k, v, attention mask x [bs, nhead, seq_len, embed_size], attmask [bs, seqlen]\n","        2. calculate the attention score\n","        3. add & norm ( dropout residual connection before add )\n","        4. feed forward network\n","        5. add & norm ( dropout residual connection before add )\n","        ensure that output have shape [bs, seqlen, embed_size*n_head]\n","\n","        '''\n","\n","        x = self.p_qkv(x) # [bs, seq_len, embed_size*3]\n","        q, k, v = torch.chunk(x, 3, dim = -1) # q, k, v [bs, seq_len, embed_size]\n","        bs, sqlen, embed_size = q.size()\n","\n","        q = q.view(bs, sqlen, self.nhead, embed_size//self.nhead).transpose(1, 2)\n","        k = k.view(bs, sqlen, self.nhead, embed_size//self.nhead).transpose(1, 2)\n","        v = v.view(bs, sqlen, self.nhead, embed_size//self.nhead).transpose(1, 2)\n","\n","        # configure mask\n","        attmask = attmask.unsqueeze(1).unsqueeze(2) # [bs, 1, 1, seq_len]\n","\n","\n","        att_score = (q @ k.transpose(-2, -1)) * (1.0/math.sqrt(q.size(-1))) # [bs, nhead, seq_len, seq_len]\n","        att_score = att_score.masked_fill(attmask == 0, -10000)\n","        att_score = F.softmax(att_score, dim = -1)\n","        att_score = self.dropout(att_score) # [bs, nhead, seq_len, seq_len]\n","        y = att_score @ v # [bs, nhead, seqlen, embed_size//nhead]\n","        y = y.transpose(1, 2).contiguous().view(bs, sqlen, embed_size)\n","        \n","        # is y need to be go through a linear layer?\n","        y = self.p_proj(y)\n","        return y\n","    \n","class FFN(nn.Module):\n","    def __init__(self, embed_size):\n","            super().__init__()\n","            self.linear1  = nn.Linear(embed_size, embed_size*4)\n","            torch.nn.init.xavier_uniform_(self.linear1.weight)\n","\n","            self.linear2 = nn.Linear(embed_size*4, embed_size)\n","            torch.nn.init.xavier_uniform_(self.linear2.weight)\n","\n","            self.gelu = nn.GELU()\n","            self.dropout = nn.Dropout(0.1)\n","        \n","    def forward(self, x):\n","            x = self.linear1(x)\n","            x = self.gelu(x)\n","            x = self.dropout(x)\n","            x = self.linear2(x)\n","            x = self.dropout(x)\n","            return x\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, embed_size, nhead, dropout,  bias=True, eps=1e-06):\n","        super().__init__()    \n","        self.selfattn = SelfAttention(embed_size, nhead, dropout)\n","        self.ffn = FFN(embed_size)\n","        self.dropout = nn.Dropout(0.1)\n","        self.norm = LayerNorm(embed_size, bias, eps)\n","\n","    def forward(self, x, mask):\n","        # x  [bs, seqlen, embed_size]\n","        x = x +  self.dropout(self.selfattn(x, mask))\n","        x = self.norm(x)\n","\t\t\n","        x = x + self.dropout(self.ffn(x))\n","        x = self.norm(x)\n","        return x, mask\n","\n","\n","\n","class TransformerEnc(nn.Module):\n","    def __init__(self, embed_size,nhead, num_layers =3, c_len = 96, device='cuda'):\n","        super(TransformerEnc, self).__init__()\n","        '''\n","            1. Encoder question and context \n","            2. CNN to get the local conte\n","        '''\n","        self.qencoder = nn.ModuleList([EncoderLayer(embed_size, nhead, 0.1).to(device) for _ in range(num_layers)])\n","        self.cencoder = nn.ModuleList([EncoderLayer(embed_size, nhead, 0.1).to(device) for _ in range(num_layers)])\n","        \n","        self.Wsim = nn.Linear(embed_size*3, 1)\n","        torch.nn.init.xavier_uniform_(self.Wsim.weight)\n","\n","        self.Wdistil = nn.Linear(embed_size*4, embed_size)\n","        torch.nn.init.xavier_uniform_(self.Wsim.weight)\n","\n","        self.synin4 = [EncoderLayer(embed_size*4, nhead, 0.1 ).to(device) for _ in range(num_layers)]\n","\n","        self.Whead1 = nn.Linear(embed_size*4, 1)\n","        torch.nn.init.xavier_uniform_(self.Whead1.weight)\n","\n","        self.Whead2 = nn.Linear(c_len, 2)\n","        torch.nn.init.xavier_uniform_(self.Whead2.weight)\n","\n","        self.dropout = nn.Dropout(0.1)\n","       \n","    def forward(self, c, q, q_mask, c_mask):\n","        # q_mask = q_mask.unsqueeze(-1)\n","        # c_mask = c_mask.unsqueeze(-1)\n","        # q_mask, c_mask [bs, seqlen]\n","        for layer in self.qencoder:\n","            q, q_mask = layer(q, q_mask)\n","        for layer in self.qencoder:\n","            c, c_mask = layer(c, c_mask)\n","        # c = self.encoder(c, c_mask) # [bs, c_len, embed_size]\n","        # q = self.encoder(q, q_mask) # [bs, q_len, embed_size]\n","        # caculate similarity matrix\n","        bs = c.size(0)\n","        c_len = c.size(1)\n","        q_len = q.size(1)\n","\n","        c_sim = c.unsqueeze(2).expand(-1, -1, q_len, -1) # [bs, c_len, q_len, embed_size]\n","        q_sim = c.unsqueeze(1).expand(-1, c_len, -1, -1) # [bs, c_len, q_len, embed_size] \n","        \n","        cq_sim = torch.mul(c_sim, q_sim) # [bs, c_len, q_len, embed_size]\n","        cqcq = torch.cat([c_sim, q_sim, cq_sim], dim=-1) # [bs, c_len, q_len, 3*embed_size]\n","        S = self.Wsim(cqcq).squeeze(-1) # similarity matrix [bs, c_len, q_len]\n","        \n","        # can meet  error such as the shape of mask can't be broadcastable with the shape of the tensor\n","        # can fix by unsqueeze the mask at dim = -1 of q_mask and c_mask\n","        # q_mask = q_mask.unsqueeze(-1)\n","\n","        S_row = S.masked_fill_(q_mask.unsqueeze(1) == 0, -10000)\n","        S_row = F.softmax(S_row, dim=-1) # [bs, c_len, q_len]\n","        A = torch.bmm(S_row, q) # [bs, c_len, embed_size]\n","\n","        # c_mask = c_mask.unsqueeze(-1)\n","        S_col = S.masked_fill_(c_mask.unsqueeze(2) == 0, -10000)\n","        S_col = F.softmax(S_col, dim = 1) # [bs, c_len, q_len]\n","\n","        B = torch.bmm(torch.bmm(S_col, S_row.transpose(1,2)), c) # [bs, c_len, embed_size]\n","\n","        distil = torch.cat([c, A, torch.mul(c, A), torch.mul(c, B)], dim = -1) # [bs, c_len, 4*embed_size]\n","        # distil = self.Wdistil(distil) # distil information [bs, c_len, embed_size]\n","        for layer in self.synin4:\n","            distil, c_mask = layer(distil, c_mask)\n","        # synin4 = self.synin4(distil) \n","        out1 = self.Whead1(distil)\n","\n","        out1 = out1.squeeze(-1)\n","        out2 = self.Whead2(self.dropout(out1))\n","\n","        return out2\n","\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:00.535151Z","iopub.status.busy":"2024-06-14T12:44:00.534877Z","iopub.status.idle":"2024-06-14T12:44:04.784192Z","shell.execute_reply":"2024-06-14T12:44:04.783247Z","shell.execute_reply.started":"2024-06-14T12:44:00.535120Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b750c130f37941ae832728013fefebb2","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bbbdae54957b4e988c4d3cf4cbb8ec10","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7216693149b45198054d0ce7edf9fe9","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/872k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"955f237263ff4c2eade24e739f5f23c2","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/877k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff67a01e30934b82934c5e93de863d5e","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/104743 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92fc9d1a881843c3ae780a6c7debd89a","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/5463 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"294cbf00714143e8947bd2c2fb59dabb","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/5463 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset = load_dataset(\"nyu-mll/glue\", \"qnli\" )\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:04.787572Z","iopub.status.busy":"2024-06-14T12:44:04.787185Z","iopub.status.idle":"2024-06-14T12:44:05.861824Z","shell.execute_reply":"2024-06-14T12:44:05.861026Z","shell.execute_reply.started":"2024-06-14T12:44:04.787545Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56b42f632c9f4a1299cf3fc52dad8d48","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1798d75c90b44e989c876ffeab3fc5c6","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37c871a4f60e4ae19199d53c6a4a2899","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8843b74d8f04c4f8945fe100f79f652","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:05.863207Z","iopub.status.busy":"2024-06-14T12:44:05.862905Z","iopub.status.idle":"2024-06-14T12:44:05.869619Z","shell.execute_reply":"2024-06-14T12:44:05.868695Z","shell.execute_reply.started":"2024-06-14T12:44:05.863181Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['question', 'sentence', 'label', 'idx'],\n","        num_rows: 104743\n","    })\n","    validation: Dataset({\n","        features: ['question', 'sentence', 'label', 'idx'],\n","        num_rows: 5463\n","    })\n","    test: Dataset({\n","        features: ['question', 'sentence', 'label', 'idx'],\n","        num_rows: 5463\n","    })\n","})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:05.871059Z","iopub.status.busy":"2024-06-14T12:44:05.870762Z","iopub.status.idle":"2024-06-14T12:44:06.031059Z","shell.execute_reply":"2024-06-14T12:44:06.030113Z","shell.execute_reply.started":"2024-06-14T12:44:05.871029Z"},"trusted":true},"outputs":[],"source":["random_train = dataset['train'].select(range(2269,12269))\n","random_val = dataset['validation'].select(range(2269,3269))\n","random_test = dataset['validation'].select(range(3269, 4269))"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:06.032515Z","iopub.status.busy":"2024-06-14T12:44:06.032195Z","iopub.status.idle":"2024-06-14T12:44:06.036312Z","shell.execute_reply":"2024-06-14T12:44:06.035395Z","shell.execute_reply.started":"2024-06-14T12:44:06.032491Z"},"trusted":true},"outputs":[],"source":["max_length = 128"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:06.040729Z","iopub.status.busy":"2024-06-14T12:44:06.040266Z","iopub.status.idle":"2024-06-14T12:44:06.949835Z","shell.execute_reply":"2024-06-14T12:44:06.949033Z","shell.execute_reply.started":"2024-06-14T12:44:06.040704Z"},"trusted":true},"outputs":[],"source":["train_data = SquadDataset(dataset['train'], 16, tokenizer, max_length)\n","validation_data = SquadDataset(random_val, 16, tokenizer, max_length)\n","test_data = SquadDataset(random_test, 16, tokenizer, max_length)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:06.951183Z","iopub.status.busy":"2024-06-14T12:44:06.950888Z","iopub.status.idle":"2024-06-14T12:44:06.958818Z","shell.execute_reply":"2024-06-14T12:44:06.957912Z","shell.execute_reply.started":"2024-06-14T12:44:06.951158Z"},"trusted":true},"outputs":[],"source":["class NAQNLI(nn.Module):\n","\tdef __init__(self, config):\n","\t\tsuper(NAQNLI, self).__init__()\n","\t\tself.w2v = WordEmbedding(config['vocab_size'], config['embed_size'], config['c_len'], config['device'],  config['BERT'])\n","\t\tself.enc = TransformerEnc(config['embed_size'], config['nhead'], config['num_layers'], config['c_len'], config['device'])\n","\t\tself.dropout = nn.Dropout(0.1)\n","\tdef forward(self, c, q, q_mask, c_mask):\n","\t\tq = self.w2v(q)\n","\t\tq = self.dropout(q)\n","\t\tc = self.w2v(c)\n","\t\tc - self.dropout(c)\n","\t\treturn self.enc(c, q, q_mask, c_mask)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:06.960157Z","iopub.status.busy":"2024-06-14T12:44:06.959890Z","iopub.status.idle":"2024-06-14T12:44:06.989876Z","shell.execute_reply":"2024-06-14T12:44:06.988912Z","shell.execute_reply.started":"2024-06-14T12:44:06.960134Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# device = 'cpu'\n","device"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:06.991326Z","iopub.status.busy":"2024-06-14T12:44:06.991044Z","iopub.status.idle":"2024-06-14T12:44:06.999138Z","shell.execute_reply":"2024-06-14T12:44:06.998202Z","shell.execute_reply.started":"2024-06-14T12:44:06.991302Z"},"trusted":true},"outputs":[],"source":["BERT = True"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:07.000869Z","iopub.status.busy":"2024-06-14T12:44:07.000251Z","iopub.status.idle":"2024-06-14T12:44:07.009488Z","shell.execute_reply":"2024-06-14T12:44:07.008689Z","shell.execute_reply.started":"2024-06-14T12:44:07.000842Z"},"trusted":true},"outputs":[],"source":["config = {\n","    'vocab_size': tokenizer.vocab_size,\n","    'embed_size': 768 if BERT else 256,\n","    'nhead': 12,\n","    'num_layers': 4,\n","    'c_len': 128,\n","    'device': device,\n","    'BERT': BERT\n","}"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:07.010647Z","iopub.status.busy":"2024-06-14T12:44:07.010360Z","iopub.status.idle":"2024-06-14T12:44:18.731506Z","shell.execute_reply":"2024-06-14T12:44:18.730507Z","shell.execute_reply.started":"2024-06-14T12:44:07.010624Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e8b628f056314065842287cd53e45c25","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69bc473c5b0743b8bbd376fdcc2426c0","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["NAQNLI(\n","  (w2v): WordEmbedding(\n","    (word2vec): Word2Vec(\n","      (embeddings): Embedding(30522, 768, padding_idx=0)\n","    )\n","    (positional_embedding): PositionalEmbedding()\n","  )\n","  (enc): TransformerEnc(\n","    (qencoder): ModuleList(\n","      (0-3): 4 x EncoderLayer(\n","        (selfattn): SelfAttention(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (p_qkv): Linear(in_features=768, out_features=2304, bias=True)\n","          (p_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (ffn): FFN(\n","          (linear1): Linear(in_features=768, out_features=3072, bias=True)\n","          (linear2): Linear(in_features=3072, out_features=768, bias=True)\n","          (gelu): GELU(approximate='none')\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (norm): LayerNorm()\n","      )\n","    )\n","    (cencoder): ModuleList(\n","      (0-3): 4 x EncoderLayer(\n","        (selfattn): SelfAttention(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (p_qkv): Linear(in_features=768, out_features=2304, bias=True)\n","          (p_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (ffn): FFN(\n","          (linear1): Linear(in_features=768, out_features=3072, bias=True)\n","          (linear2): Linear(in_features=3072, out_features=768, bias=True)\n","          (gelu): GELU(approximate='none')\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (norm): LayerNorm()\n","      )\n","    )\n","    (Wsim): Linear(in_features=2304, out_features=1, bias=True)\n","    (Wdistil): Linear(in_features=3072, out_features=768, bias=True)\n","    (Whead1): Linear(in_features=3072, out_features=1, bias=True)\n","    (Whead2): Linear(in_features=128, out_features=2, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n",")"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model = NAQNLI(config)\n","model.to(device)\n","# model = torch.compile(model)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:18.733741Z","iopub.status.busy":"2024-06-14T12:44:18.732880Z","iopub.status.idle":"2024-06-14T12:44:18.739553Z","shell.execute_reply":"2024-06-14T12:44:18.738610Z","shell.execute_reply.started":"2024-06-14T12:44:18.733704Z"},"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=0.001,betas=(0.8, 0.999), eps=1e-07, weight_decay=0.0001)\n","# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_data)*20, eta_min=0.006*0.1, last_epoch=-1, verbose=False)\n","critereon = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:18.741063Z","iopub.status.busy":"2024-06-14T12:44:18.740729Z","iopub.status.idle":"2024-06-14T12:44:18.753311Z","shell.execute_reply":"2024-06-14T12:44:18.752450Z","shell.execute_reply.started":"2024-06-14T12:44:18.741031Z"},"trusted":true},"outputs":[],"source":["def train(model, train_data, optimizer, critereon, epochs):\n","\tt0 = time.time()\n","\tfor epoch in range(epochs):\n","\t\tmodel.train()\n","\t\trunning_loss = 0.0\n","\t\tfor q, c, labels in (train_data):\n","\t\t\tmodel.zero_grad()\n","\t\t\tq_i = q['input_ids'].to(device)\n","\t\t\tc_i = c['input_ids'].to(device)\n","\t\t\tq_mask = q['attention_mask'].to(device)\n","\t\t\tc_mask = c['attention_mask'].to(device)\n","\t\t\t# with torch.autocast(device_type=device, dtype=torch.float16):\n","\t\t\toutput = model(c_i, q_i, q_mask, c_mask)\n","\t\t\tlabels = labels.long().to(device)\n","\t\t\tloss = critereon(output,labels)\n","\t\t\tloss.backward()\n","\t\t\ttorch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\t\t\toptimizer.step()\n","\t\t\trunning_loss += loss.item()\n","\t\tprint(f\"Epoch {epoch} Loss: {loss.item()/len(train_data)}\")\n","\tt1 = time.time()\t\t\n","\tprint(f\"Training time: {t1-t0}\")\n","\t"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:38.977516Z","iopub.status.busy":"2024-06-14T12:44:38.976704Z","iopub.status.idle":"2024-06-14T12:44:38.985656Z","shell.execute_reply":"2024-06-14T12:44:38.984456Z","shell.execute_reply.started":"2024-06-14T12:44:38.977475Z"},"trusted":true},"outputs":[{"data":{"text/plain":["59056388"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["sum(p.numel() for p in model.parameters() if p.requires_grad)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T12:44:44.771521Z","iopub.status.busy":"2024-06-14T12:44:44.770797Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0 Loss: 0.00012194811706053532\n","Epoch 1 Loss: 0.00012966014964900638\n","Epoch 2 Loss: 0.00011288484253190721\n"]}],"source":["train(model, train_data, optimizer, critereon, 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), '/kaggle/working/TransQNLI.pth')"]},{"cell_type":"code","execution_count":22,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-14T10:18:46.327597Z","iopub.status.busy":"2024-06-14T10:18:46.326959Z","iopub.status.idle":"2024-06-14T10:18:46.579243Z","shell.execute_reply":"2024-06-14T10:18:46.577846Z","shell.execute_reply.started":"2024-06-14T10:18:46.327557Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'model_weights.pth'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming `model` is an instance of the same architecture you trained earlier\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_weights.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model_weights.pth'"]}],"source":["# Assuming `model` is an instance of the same architecture you trained earlier\n","model.load_state_dict(torch.load('model_weights.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def evaluation(model, validation_data, critereon):\n","\tmodel.eval()\n","\trunning_loss = 0.0\n","\ttotal = 0\n","\tcorrect = 0\n","\t# with torch.no_grad():\n","\tfor q, c, labels in (validation_data):\n","\t\t\tq_i = q['input_ids'].to(device)\n","\t\t\tc_i = c['input_ids'].to(device)\n","\t\t\tq_mask = q['attention_mask'].to(device)\n","\t\t\tc_mask = c['attention_mask'].to(device)\n","\t\t\twith torch.no_grad():\n","\t\t\t# with torch.autocast(device_type=device, dtype=torch.bfloat16):\n","\t\t\t\toutput = model(c_i, q_i, q_mask, c_mask)\n","\t\t\t\tlabels = labels.long().to(device)\n","\t\t\t\tloss = critereon(output,labels\n","\t\t\t\trunning_loss += loss.item()\n","\t\t\t\t_, predicted = torch.argmax(output, -1)\n","\t\t\t\ttotal += labels.size(0)\n","\t\t\t\tcorrect += (predicted == labels).sum().item()\n","\tprint(f\"Validation Loss: {running_loss/len(validation_data)}\")\n","\tprint(f\"Accuracy: {correct/total}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["evaluation(model, validation_data, critereon)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["evaluation(model, train_data, critereon)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def predict(model, questions, sentences, tokenizer, max_len):\n","\tmodel.eval()\n","\twith torch.no_grad():\n","\tq = tokenizer(questions, max_length = max_len, padding='max_length', truncation=True, return_tensors='pt')\n","\tc = tokenizer(sentences, max_length = max_len, padding='max_length', truncation=True, return_tensors='pt')\n","\tq_i = q['input_ids'].to(device)\n","\tc_i = c['input_ids'].to(device)\n","\tq_mask = q['attention_mask'].to(device)\n","\tc_mask = c['attention_mask'].to(device)\n","\toutput = model(c_i, q_i, q_mask, c_mask)\n","\t_, predicted = torch.max(output, 1, dim=-1, keepdim=True)\n","\treturn predicted"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def accuracy_score(model, validation_data, critereon):\n","\tmodel.eval()\n","\trunning_loss = 0.0\n","\tcorrect = 0\n","\ttotal = 0\n","\twith torch.no_grad():\n","\t\tfor q, c, labels in (validation_data):\n","\t\t\tq_i = q['input_ids'].to(device)\n","\t\t\tc_i = c['input_ids'].to(device)\n","\t\t\tq_mask = q['attention_mask'].to(device)\n","\t\t\tc_mask = c['attention_mask'].to(device)\n","\t\t\twith torch.autocast(device_type=device, dtype=torch.bfloat16):\n","\t\t\t\toutput = model(c_i, q_i, q_mask, c_mask)\n","\t\t\t\tlabels = labels.long().to(device)\n","\t\t\t\tloss = critereon(output,labels )\n","\t\t\trunning_loss += loss.item()\n","\t\t\t_, predicted = torch.max(output, 1)\n","\t\t\ttotal += labels.size(0)\n","\t\t\tcorrect += (predicted == labels).sum().item()\n","\tprint(f\"Accuracy: {correct/total}\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
