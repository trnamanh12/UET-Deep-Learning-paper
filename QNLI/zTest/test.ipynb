{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"nyu-mll/glue\", \"qnli\")\n",
    "\n",
    "'''\n",
    "# you can use any of the following config names as a second argument:\n",
    "\"ax\", \"cola\", \"mnli\", \"mnli_matched\", \n",
    "\"mnli_mismatched\", \"mrpc\", \"qnli\", \"qqp\", \n",
    "\"rte\", \"sst2\", \"stsb\", \"wnli\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104743, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.set_format(type='torch', columns=['sentence', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': ['When did the third Digimon series begin?',\n",
       "  'Which missile batteries often have individual launchers several kilometres from one another?'],\n",
       " 'sentence': ['Unlike the two seasons before it and most of the seasons that followed, Digimon Tamers takes a darker and more realistic approach to its story featuring Digimon who do not reincarnate after their deaths and more complex character development in the original Japanese.',\n",
       "  'When MANPADS is operated by specialists, batteries may have several dozen teams deploying separately in small sections; self-propelled air defence guns may deploy in pairs.'],\n",
       " 'label': [1, 1],\n",
       " 'idx': [0, 1]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'sentence', 'label', 'idx'],\n",
       "        num_rows: 104743\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'sentence', 'label', 'idx'],\n",
       "        num_rows: 5463\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'sentence', 'label', 'idx'],\n",
       "        num_rows: 5463\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unlike the two seasons before it and most of the seasons that followed, Digimon Tamers takes a darker and more realistic approach to its story featuring Digimon who do not reincarnate after their deaths and more complex character development in the original Japanese.',\n",
       " 'When MANPADS is operated by specialists, batteries may have several dozen teams deploying separately in small sections; self-propelled air defence guns may deploy in pairs.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0:2]['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 45227, 10105, 10551, 21396, 11360, 10271, 10111, 10992, 10108, 10105, 21396, 10189, 15689, 117, 83306, 27324, 10901, 19135, 169, 25100, 10165, 10111, 10798, 13486, 29025, 23068, 10114, 10474, 13617, 17846, 83306, 10479, 10149, 10472, 74720, 15983, 36884, 10662, 10455, 50438, 10111, 10798, 17217, 15092, 13405, 10106, 10105, 11364, 13847, 119, 102], [101, 12242, 73020, 52099, 33953, 10124, 19301, 10155, 64956, 10107, 117, 72781, 11387, 10529, 11736, 84956, 14404, 10104, 91823, 10230, 91614, 10106, 12474, 30293, 132, 16567, 118, 30045, 14000, 10162, 12566, 47245, 31199, 11387, 10104, 91823, 10106, 55736, 119, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_encode_plus(dataset['train'][0:2]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thu 2 cach implement khac nhau\n",
    "# Case 1: using output hidden state cua question encoder is input of context encoder, then use the output of context encoder to predict the label\n",
    "# Case 2: using output hidden state of context encoder is the input to question encoder, then use the output of question encoder to predict the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104743"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'When did the third Digimon series begin?',\n",
       " 'sentence': 'Unlike the two seasons before it and most of the seasons that followed, Digimon Tamers takes a darker and more realistic approach to its story featuring Digimon who do not reincarnate after their deaths and more complex character development in the original Japanese.',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 12242, 12172, 10105, 12628, 83306, 11366, 16135,   136,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,   160, 39187, 10237, 45174, 72781, 12899, 10529, 16080, 29227,\n",
       "         10901, 11736, 20127, 10188, 10464, 12864,   136,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(dataset['train'][0:2]['question'], padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "\t'''\n",
    "\t- Creates batches dynamically by padding to the length of largest example\n",
    "\t  in a given batch.\n",
    "\t- Calulates character vectors for contexts and question.\n",
    "\t- Returns tensors for training.\n",
    "\t'''\n",
    "\t\n",
    "\tdef __init__(self, data, batch_size, tokenizer):\n",
    "\t\t\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tdata = [data[i:i+self.batch_size] for i in range(0, len(data), self.batch_size)]\n",
    "\t\tself.data = data\n",
    "\t\tself.tokenizer = tokenizer\n",
    "\t\t\n",
    "\t\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.data)\n",
    "\t\n",
    "\tdef __iter__(self):\n",
    "\t\t'''\n",
    "\t\tCreates batches of data and yields them.\n",
    "\t\t\n",
    "\t\tEach yield comprises of:\n",
    "\t\t:padded_context: padded tensor of contexts for each batch \n",
    "\t\t:padded_question: padded tensor of questions for each batch \n",
    "\t\t:label: \n",
    "\t\t\n",
    "\t\t'''\n",
    "\t\t\n",
    "\t\tfor batch in self.data:\n",
    "\t\t\tquestion = self.tokenizer(batch['question'], padding=True, truncation=True, return_tensors='pt', max_length=96)['input_ids']\n",
    "\t\t\tcontext = self.tokenizer(batch['sentence'], padding=True, truncation=True, return_tensors='pt', max_length=256)['input_ids']\n",
    "\t\t\tlabel = torch.BoolTensor(batch['label'])\n",
    "\t\t\t\n",
    "\t\t\tyield question, context, label\n",
    "\t\t\t\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104743"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = SquadDataset(dataset['train'], 8, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in squad:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.utils.data.DataLoader(squad, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNqnli(nn.Module):\n",
    "\tdef __init__(self, question_size, context_size, hidden_size, num_layers, num_classes):\n",
    "\t\tsuper(RNNqnli, self).__init__()\n",
    "\t\tself.hidden_size = hidden_size # hidden size of RNN\n",
    "\t\tself.num_layers = num_layers\t# number of layers of RNN\n",
    "\t\tself.rnn_question = nn.RNN(question_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "\t\t# output of question encoder [batch_size, seq_len, hidden_size * 2]\n",
    "\n",
    "\t\tself.rnn_context = nn.RNN(context_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "\t\t# output of context encoder [batch_size, seq_len, hidden_size * 2]\n",
    "\t\t\n",
    "\t\tself.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mTensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m], [\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.max(torch.Tensor([[1,2,3], [4,5,6]]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.randn(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(s, dim=-1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = F.softmax(torch.max(s, dim=2)[0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 1, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1,2,3).unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_string = ['this', 'is', 'a', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['t', 'h', 'i', 's'], ['i', 's'], ['a'], ['t', 'e', 'x', 't']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(a) for a in list_string ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=48, nhead=4, batch_first=True)\n",
    "src = torch.rand(5, 3, 48)\n",
    "out = encoder_layer(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 48])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[1,2,3], [4,5,6], [7,8,9]])\n",
    "b = torch.Tensor([[1,1,1], [1,1,1], [1,1,1]])\n",
    "c = torch.mul(a,b)\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = lambda:[0,0,0,0]\n",
    "y = x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = deque([(0, -1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([(0, -1)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def min_cost_to_paint_tree(N, edges):\n",
    "    from collections import defaultdict, deque\n",
    "    \n",
    "    # Create adjacency list for the tree\n",
    "    tree = defaultdict(list)\n",
    "    for u, v in edges:\n",
    "        tree[u].append(v)\n",
    "        tree[v].append(u)\n",
    "    \n",
    "    # BFS to calculate the minimum cost to paint all vertices\n",
    "    def bfs(start):\n",
    "        visited = set()\n",
    "        queue = deque([(start, -1)])  # (current_node, parent_node)\n",
    "        moves = 0\n",
    "        \n",
    "        while queue:\n",
    "            node, parent = queue.popleft()\n",
    "            visited.add(node)\n",
    "            parent = node\n",
    "            for neighbor in tree[node]:\n",
    "                if neighbor not in visited:\n",
    "                    queue.append((neighbor, node))\n",
    "                    if parent != -1:\n",
    "                        moves += 1  # Action 2 (moving piece) costs 1\n",
    "        \n",
    "        return moves\n",
    "    \n",
    "    # We can start BFS from any node, let's choose node 1\n",
    "    return bfs(1)\n",
    "\n",
    "# Example 1\n",
    "N = 4\n",
    "edges = [(1, 2), (1, 3), (1, 4)]\n",
    "print(min_cost_to_paint_tree(N, edges))  # Output: 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 6.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[[1,2,3], [4,5,6], [7,8,9]], [[1,2,3], [4,5,6], [7,8,9]]])\n",
    "a.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practic1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
